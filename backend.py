#æœ€ç»ˆå‘å¸ƒç‰ˆæœ¬
import hashlib
import json
import bcrypt
import logging
import os
import re
import shutil
import time
import webbrowser
import sys
import xml
import uuid
import csv
from datetime import datetime
from logging.handlers import TimedRotatingFileHandler
from pathlib import Path
from flask import Flask, jsonify, render_template, request, Response, session, g, abort, stream_with_context
from re import compile, Pattern, Match
from typing import Iterator, TextIO, AnyStr
from xml.dom.minicompat import NodeList
from xml.dom.minidom import Document, Element
from openai import OpenAI
import random
import threading
import socket
import asyncio
import websockets
import queue


def get_base_path():
    """ æ™ºèƒ½è·å–è¿è¡ŒåŸºç¡€è·¯å¾„ """
    if getattr(sys, 'frozen', False):
        # æ‰“åŒ…æ¨¡å¼ï¼šexeæ‰€åœ¨ç›®å½•ï¼ˆdist/backendï¼‰
        return Path(sys.executable).parent.absolute()
    # å¼€å‘æ¨¡å¼ï¼šè„šæœ¬æ‰€åœ¨ç›®å½•
    return Path(__file__).parent.absolute()

# å…¨å±€åŸºç¡€è·¯å¾„
BASE_PATH = get_base_path()

# åˆ›å»ºå¯¼å‡ºç›®å½•
EXPORTS_DIR = BASE_PATH / 'exports'
EXPORTS_DIR.mkdir(parents=True, exist_ok=True)

# Flaské…ç½®ï¼ˆåŠ¨æ€è·¯å¾„ï¼‰
app = Flask(
    __name__,
    static_folder=str(BASE_PATH / 'static'),
    template_folder=str(BASE_PATH / 'templates'),
    static_url_path=''
)
app.jinja_env.filters['tojson'] = json.dumps
app.secret_key = 'your_random_secret_key'

# æ·»åŠ Jinja2å…¨å±€è¿‡æ»¤å™¨
app.jinja_env.globals.update(tojson=json.dumps)

# æ‰€æœ‰è·¯å¾„å®šä¹‰ä½¿ç”¨ç»å¯¹è·¯å¾„
SONGS_DIR = BASE_PATH / 'static' / 'songs'
BACKUP_DIR = BASE_PATH / 'static' / 'backups'
LOG_DIR = BASE_PATH / 'logs'

# è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶ï¼‰
for path in [SONGS_DIR, BACKUP_DIR, LOG_DIR]:
    path.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
log_format = '%(asctime)s - %(levelname)s - %(message)s'
log_handler = TimedRotatingFileHandler(os.path.join(LOG_DIR, 'upload.log'),
                                       when='midnight',
                                       interval=1,
                                       backupCount=7,
                                       encoding='utf-8')
log_handler.setFormatter(logging.Formatter(log_format))
app.logger.addHandler(log_handler)

# è®¾ç½®æ—¥å¿—çº§åˆ«ï¼Œæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨è°ƒè¯•æ—¥å¿—
log_level = logging.DEBUG if os.environ.get('DEBUG_LOGGING', '0') == '1' else logging.INFO
app.logger.setLevel(log_level)

useu = ""

# ==== AMLL -> å‰ç«¯ çš„å®æ—¶æ€»çº¿ï¼ˆSSEï¼‰ ====
# å…¨å±€çŠ¶æ€ï¼ˆç»™å‰ç«¯å¿«ç…§ç”¨ï¼‰
AMLL_STATE = {
    "song": {"musicName": "", "artists": [], "duration": 0},
    "progress_ms": 0,
    "lines": [],
    "last_update": 0
}
# äº‹ä»¶é˜Ÿåˆ—ï¼ˆç»™å‰ç«¯å®æ—¶æ¨é€ç”¨ï¼‰
AMLL_QUEUE = queue.Queue(maxsize=1000)

# æ·»åŠ å…¨å±€å˜é‡å­˜å‚¨AIç¿»è¯‘è®¾ç½®
AI_TRANSLATION_SETTINGS = {
    'api_key': '',
    'system_prompt': '''ä¸€ä¸ªä¸“ä¸šçš„æ­Œè¯ç¿»è¯‘åŠ©æ‰‹ã€‚ä¼šæŒ‰ç…§ä»¥ä¸‹è§„åˆ™ç¿»è¯‘æ­Œè¯ï¼š
1. ä¿æŒåŸæ–‡çš„æ„å¢ƒå’Œæƒ…æ„Ÿï¼šä»¤äººæ„ŸåŠ¨çš„æ­Œè¯ï¼Œä¸ä¸€å®šéœ€è¦åä¸½çš„è¯è—»ï¼Œä½†ä¸€å®šæœ‰çœŸæŒšçš„æ„Ÿæƒ…ã€‚
2. ç¡®ä¿æ¯è¡Œç¿»è¯‘éƒ½å‡†ç¡®å¯¹åº”åŸæ–‡
3. ç¿»è¯‘ç»“æœå¿…é¡»ä¿æŒåºå·æ ¼å¼ï¼Œä¾‹å¦‚ï¼š1.ç¿»è¯‘å†…å®¹
4. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–è¯´æ˜
5. ç¡®ä¿æ¯è¡Œç¿»è¯‘éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸è¦å°†å¤šè¡Œåˆå¹¶''',
    'provider': 'deepseek',
    'base_url': 'https://api.deepseek.com',
    'model': 'deepseek-reasoner',
    'expect_reasoning': True
}

# ===== è§£æ.lysæ ¼å¼æ­Œè¯çš„å·¥å…·å‡½æ•° =====
def compute_disappear_times(lines, *, delta1=500, delta2=0, t_anim=700):
    """
    å¯¹æ¯ä¸€è¡Œï¼ˆå« syllables æ•°ç»„ï¼Œå•ä½ç§’ï¼‰è®¡ç®— disappearTimeï¼ˆå•ä½æ¯«ç§’ï¼‰ã€‚
    è§„åˆ™ä¸ parse_lys ä¸­ä¿æŒä¸€è‡´ï¼š
    - è¡Œæœ« E_i ä¸ä¸‹ä¸€è¡Œé¦– N_next çš„å…³ç³»ï¼ŒDELTA1/DELTA2 è°ƒæ•´
    - ä¸ä¸Šä¸€è¡Œæœ€ç»ˆ T_disappear_prev çš„"ç¤¼è®©/è¡”æ¥"
    """
    if not lines:
        return lines

    # å¤åˆ¶ç´¢å¼•ï¼Œè®¡ç®—æŒ‰å¼€å§‹æ—¶é—´æ’åºï¼Œä¸æ”¹å˜åŸé¡ºåº
    for idx, line in enumerate(lines):
        line['__orig_idx'] = idx

    def first_start_ms(line):
        s = line.get('syllables', [])
        if not s:
            return float('inf')
        return int(float(s[0]['startTime']) * 1000)

    def last_end_ms(line):
        s = line.get('syllables', [])
        if not s:
            return 0
        last = s[-1]
        return int(float(last['startTime']) * 1000 + float(last['duration']) * 1000)

    sorted_lines = sorted(lines, key=first_start_ms)

    for i, line in enumerate(sorted_lines):
        E_i = last_end_ms(line)
        # å€™é€‰ï¼šè‡ªèº«ç»“æŸ
        T_candidate = E_i

        # ä¸‹ä¸€è¡Œé¦–
        N_next = float('inf')
        if i + 1 < len(sorted_lines):
            N_next = first_start_ms(sorted_lines[i + 1])
            # è´´è¾¹è°ƒæ•´
            if N_next - delta1 <= E_i <= N_next + delta2:
                T_candidate = N_next + delta2

        # ä¸ä¸Šä¸€è¡Œæœ€ç»ˆæ—¶é—´çš„ç¤¼è®©/è¡”æ¥
        if i > 0:
            T_prev_final = sorted_lines[i - 1].get('disappearTime', 0)
            if T_prev_final > T_candidate:
                # é‡å ï¼šå…è®¸è´´è¾¹ï¼Œæ‹‰å¼€åŠ¨ç”»æ—¶é—´
                T_final = min(N_next, E_i + t_anim, T_prev_final + t_anim)
            else:
                T_final = T_candidate
        else:
            T_final = T_candidate

        line['disappearTime'] = T_final
        line['debug_times'] = {
            'E_i': E_i,
            'T_candidate': T_candidate,
            'T_prev_final': sorted_lines[i - 1].get('disappearTime', 0) if i > 0 else 0,
            'final': T_final
        }

    # å†™å›åŸé¡ºåº
    disappear_map = {l['__orig_idx']: l['disappearTime'] for l in sorted_lines}
    debug_map = {l['__orig_idx']: l['debug_times'] for l in sorted_lines}
    for line in lines:
        line['disappearTime'] = disappear_map.get(line['__orig_idx'], 0)
        line['debug_times'] = debug_map.get(line['__orig_idx'], {})
        if '__orig_idx' in line:
            del line['__orig_idx']

    # å¯é€‰ï¼šè°ƒè¯•æ—¥å¿—
    try:
        app.logger.debug("--- AMLL Disappear Time Calc ---")
        for line in lines:
            dbg = line.get('debug_times', {})
            app.logger.debug(f"E_i:{dbg.get('E_i')} T_cand:{dbg.get('T_candidate')} "
                             f"T_prev:{dbg.get('T_prev_final')} final:{dbg.get('final')}")
        app.logger.debug("--------------------------------")
    except Exception:
        pass

    return lines


def parse_lys(lys_content):
    """
    è§£æ.lysæ ¼å¼çš„é€éŸ³èŠ‚æ­Œè¯æ–‡ä»¶ï¼Œå¹¶è®¡ç®—æ¯è¡Œçš„æ¶ˆå¤±æ—¶æœºï¼ˆdisappearTimeï¼Œå•ä½æ¯«ç§’ï¼‰ã€‚
    è¿”å›çš„æ­Œè¯åˆ—è¡¨å°†ä¿æŒæ–‡ä»¶ä¸­çš„åŸå§‹é¡ºåºã€‚
    """
    lyrics_data = []
    block_regex = re.compile(r'(.+?)\((\d+),(\d+)\)')
    cleanup_regex = re.compile(r'\(\d+,\d+\)')
    offset_regex = re.compile(r'\[offset:\s*(-?\d+)\s*\]')
    last_align = 'left'
    offset = 0

    # æŸ¥æ‰¾å¹¶è§£æ offset
    offset_match = offset_regex.search(lys_content)
    if offset_match:
        offset = int(offset_match.group(1))

    for line in lys_content.splitlines():
        # è·³è¿‡å…ƒæ•°æ®è¡Œ
        if line.startswith('[from:') or line.startswith('[id:') or line.startswith('[offset:'):
            continue
        
        # ä¿®æ”¹æ ‡è®°è§£æé€»è¾‘ï¼šå…è®¸ç©º[]ï¼Œåªæ’é™¤éæ•°å­—çš„æ ‡è®°
        content_match = re.match(r'\[(?P<marker>\d*)\](?P<content>.*)', line)
        if not content_match:
            continue
        marker = content_match.group('marker')
        # æ–°å¢ï¼šå¦‚æœæ ‡è®°ä¸æ˜¯ç©ºä¸”ä¸æ˜¯çº¯æ•°å­—ï¼Œåˆ™è·³è¿‡
        if marker != '' and not marker.isdigit():
            continue
        content = content_match.group('content')
        align = 'left'
        font_size = 'normal'
        
        if not marker:
            align = 'center'
        elif marker in ['2', '5']:
            align = 'right'
        elif marker in ['6', '7', '8']:
            align = last_align
            font_size = 'small'
        
        syllables = []
        full_line_text = ""
        matches = block_regex.finditer(content)
        for match in matches:
            text_part, start_ms, duration_ms = match.groups()
            cleaned_text = cleanup_regex.sub('', text_part)
            cleaned_text = re.sub(r'[()]', '', cleaned_text)
            if cleaned_text:
                syllables.append({
                    'text': cleaned_text,
                    'startTime': (int(start_ms) + offset) / 1000.0, # åº”ç”¨ offset
                    'duration': int(duration_ms) / 1000.0
                })
                full_line_text += cleaned_text
        
        if syllables:
            lyrics_data.append({
                'line': full_line_text,
                'syllables': syllables,
                'style': {
                    'align': align,
                    'fontSize': font_size
                }
            })
        last_align = align
    
    # å¦‚æœæ²¡æœ‰æ­Œè¯æ•°æ®ï¼Œç›´æ¥è¿”å›
    if not lyrics_data:
        return []

    # === ç»Ÿä¸€ç”¨é€šç”¨å‡½æ•°è®¡ç®—æ¶ˆå¤±æ—¶æœº ===
    compute_disappear_times(lyrics_data, delta1=500, delta2=0, t_anim=700)
    return lyrics_data

@app.route('/')
def index():
    json_files = []
    static_dir = BASE_PATH / 'static'
    for file in static_dir.iterdir():
        if file.suffix == '.json':
            mtime = file.stat().st_mtime
            with open(file, 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)
                    json_files.append({
                        'filename': file.name,
                        'data': data,
                        'mtime': mtime  # æ·»åŠ ä¿®æ”¹æ—¶é—´
                    })
                except:
                    continue
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    json_files.sort(key=lambda x: x['mtime'], reverse=True)
    return render_template('Famyliam_Everywhere.html', json_files=json_files)

# åœ¨Flaskåº”ç”¨ä¸­æ·»åŠ è‡ªå®šä¹‰è¿‡æ»¤å™¨
@app.template_filter('escape_js')
def escape_js_filter(s):
    return json.dumps(str(s))[1:-1]  # ç§»é™¤å¤–å±‚çš„å¼•å·


@app.route('/backup_file', methods=['POST'])
def backup_file():
    if not is_request_allowed():
        return abort(403)
    file_path = request.json.get('file_path')
    if not BACKUP_DIR.exists():
        BACKUP_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = BACKUP_DIR / f"{Path(file_path).name}.{timestamp}"
    shutil.copy2(file_path, backup_path)
    return jsonify({'status': 'success'})


@app.route('/delete_json', methods=['POST'])
def delete_json():
    if not is_request_allowed():
        return abort(403)
    data = request.json
    filename = data['filename']
    json_path = BASE_PATH / 'static' / filename

    try:
        # åªå¤‡ä»½å’Œåˆ é™¤JSONæ–‡ä»¶æœ¬èº«ï¼Œä¸åˆ é™¤å…³è”çš„æ­Œè¯ã€éŸ³ä¹ç­‰æ–‡ä»¶
        delete_backup_dir = BACKUP_DIR / 'permanent'
        delete_backup_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        if json_path.exists():
            # å¤‡ä»½JSONæ–‡ä»¶
            relative_path = json_path.relative_to(BASE_PATH)
            backup_path = delete_backup_dir / f"{str(relative_path).replace('/', '__')}.{timestamp}"
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(json_path, backup_path)

            # åˆ é™¤JSONæ–‡ä»¶
            json_path.unlink()

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/restore_file', methods=['POST'])
def restore_file():
    if not is_request_allowed():
        return abort(403)
    file_path = request.json.get('file_path')
    try:
        # å¦‚æœæ˜¯å¤‡ä»½æ–‡ä»¶è·¯å¾„
        if 'backups' in file_path:
            backup_path = Path(file_path.replace('http://127.0.0.1:5000/backups/',
                                            str(BACKUP_DIR) + '/'))
            original_name = '.'.join(
                backup_path.name.split('.')[:-1])
            restore_path = BASE_PATH / 'static' / original_name
            shutil.copy2(backup_path, restore_path)
        else:
            # è·å–æ‰€æœ‰å…³è”æ–‡ä»¶å¤‡ä»½
            related_files = get_related_files(file_path)  # æ–°å¢å…³è”æ–‡ä»¶è·å–æ–¹æ³•
            backups = []

            # ä¸ºæ¯ä¸ªå…³è”æ–‡ä»¶åˆ›å»ºæ¢å¤ä»»åŠ¡
            for file in related_files:
                file_backups = []
                for backup in BACKUP_DIR.iterdir():
                    if backup.name.startswith(Path(file).name):
                        file_backups.append(backup)

                if not file_backups:
                    continue

                file_backups.sort(reverse=True)
                latest_backup = file_backups[0]
                shutil.copy2(latest_backup, file)  # æ¢å¤æ–‡ä»¶

                # æ¸…ç†æ—§å¤‡ä»½ä¿æŒ7ä¸ªç‰ˆæœ¬
                for old_backup in file_backups[7:]:
                    old_backup.unlink()

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


def get_related_files(json_path):
    """è·å–ä¸JSONæ–‡ä»¶å…³è”çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„"""
    related_files = [json_path]

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # è·å–æ­Œè¯ç›¸å…³æ–‡ä»¶
        lyrics_info = data['meta'].get('lyrics', '').split('::')
        for path in lyrics_info[1:4]:  # æ­Œè¯ã€ç¿»è¯‘ã€éŸ³è¯‘è·¯å¾„
            if path and path != '!':
                local_path = path.replace('http://127.0.0.1:5000/songs/',
                                          str(SONGS_DIR) + '/')
                related_files.append(local_path)

        # è·å–éŸ³é¢‘æ–‡ä»¶
        if 'song' in data:
            local_music = data['song'].replace('http://127.0.0.1:5000/songs/',
                                               str(SONGS_DIR) + '/')
            related_files.append(local_music)

        # è·å–ä¸“è¾‘å›¾
        if 'albumImgSrc' in data['meta']:
            local_img = data['meta']['albumImgSrc'].replace(
                'http://127.0.0.1:5000/songs/', str(SONGS_DIR) + '/')
            related_files.append(local_img)

    except Exception as e:
        print(f"Error getting related files: {str(e)}")

    return list(set(related_files))  # å»é‡


@app.route('/update_json', methods=['POST'])
def update_json():
    if not is_request_allowed():
        return abort(403)
    data = request.json
    file_path = BASE_PATH / 'static' / data["filename"]

    try:
        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        if not BACKUP_DIR.exists():
            BACKUP_DIR.mkdir(parents=True, exist_ok=True)

        # å¤‡ä»½åŸæ–‡ä»¶
        backup_path = BACKUP_DIR / f"{data['filename']}.{int(time.time())}"
        if file_path.exists():  # åªåœ¨æ–‡ä»¶å­˜åœ¨æ—¶è¿›è¡Œå¤‡ä»½
            shutil.copy2(file_path, backup_path)

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data['content'], f, ensure_ascii=False, indent=2)

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/save_lyrics', methods=['POST'])
def save_lyrics():
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.json
        if not data or 'path' not in data or 'content' not in data:
            app.logger.error("æ— æ•ˆçš„è¯·æ±‚æ•°æ®: ç¼ºå°‘å¿…è¦çš„å­—æ®µ")
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'})

        # éªŒè¯è·¯å¾„
        if not data['path'] or data['path'] == '.' or data['path'] == './':
            app.logger.error(f"æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„: {data['path']}")
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„'})

        # éªŒè¯è·¯å¾„æ ¼å¼
        if not data['path'].startswith('http://127.0.0.1:5000/songs/'):
            app.logger.error(f"æ— æ•ˆçš„è·¯å¾„æ ¼å¼: {data['path']}")
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„è·¯å¾„æ ¼å¼'})

        file_path = Path(data['path'].replace('http://127.0.0.1:5000/songs/',
                                         str(SONGS_DIR) + '/'))
        content = data['content']

        # éªŒè¯æ–‡ä»¶è·¯å¾„
        if not file_path.is_absolute():
            app.logger.error(f"æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„: {file_path}, å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„")
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„'})

        # éªŒè¯æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•ä¸­
        try:
            file_path.relative_to(SONGS_DIR)
        except ValueError:
            app.logger.error(f"æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­: {file_path}")
            return jsonify({'status': 'error', 'message': 'æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•ä¸­'})

        # éªŒè¯æ–‡ä»¶å
        if not file_path.name or file_path.name == '.' or file_path.name == '..':
            app.logger.error(f"æ— æ•ˆçš„æ–‡ä»¶å: {file_path.name}")
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # ä¿®æ”¹ä¿å­˜é€»è¾‘ï¼Œæ·»åŠ ç›®å½•åˆ›å»º
        file_dir = file_path.parent
        if not file_dir.exists():
            try:
                file_dir.mkdir(parents=True, exist_ok=True)
                app.logger.info(f"åˆ›å»ºç›®å½•æˆåŠŸ: {file_dir}")
            except Exception as e:
                app.logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {file_dir}, é”™è¯¯: {str(e)}, æƒé™: {oct(file_dir.parent.stat().st_mode)[-3:] if file_dir.parent.exists() else 'N/A'}")
                return jsonify({'status': 'error', 'message': f'åˆ›å»ºç›®å½•å¤±è´¥: {str(e)}'})

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»º
        if not file_path.exists():
            try:
                open(file_path, 'w', encoding='utf-8').close()
                app.logger.info(f"åˆ›å»ºæ–‡ä»¶æˆåŠŸ: {file_path}")
            except Exception as e:
                app.logger.error(f"åˆ›å»ºæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}, æƒé™: {oct(file_path.parent.stat().st_mode)[-3:] if file_path.parent.exists() else 'N/A'}")
                return jsonify({'status': 'error', 'message': f'åˆ›å»ºæ–‡ä»¶å¤±è´¥: {str(e)}'})

        # æ‰©å±•å¤‡ä»½é€»è¾‘ï¼šåŒæ—¶å¤‡ä»½å…³è”çš„JSONæ–‡ä»¶
        if '/songs/' in data['path']:
            json_files = find_related_json(str(file_path))  # æ–°å¢æŸ¥æ‰¾å…³è”JSONæ–¹æ³•
            for json_file in json_files:
                try:
                    json_path = Path(json_file)
                    if not json_path.is_absolute():
                        app.logger.warning(f"è·³è¿‡æ— æ•ˆçš„JSONæ–‡ä»¶è·¯å¾„: {json_file}")
                        continue
                    backup_path = BACKUP_DIR / f"{json_path.name}.{int(time.time())}"
                    shutil.copy2(json_path, backup_path)
                    app.logger.info(f"å¤‡ä»½JSONæ–‡ä»¶æˆåŠŸ: {json_path} -> {backup_path}")
                except Exception as e:
                    app.logger.error(f"å¤‡ä»½JSONæ–‡ä»¶å¤±è´¥: {json_file}, é”™è¯¯: {str(e)}, æƒé™: {oct(Path(json_file).parent.stat().st_mode)[-3:] if Path(json_file).parent.exists() else 'N/A'}")

        # å¤‡ä»½ç®¡ç†(ä¿ç•™æœ€è¿‘7ä¸ªç‰ˆæœ¬)
        if file_path.exists():
            try:
                # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
                if not BACKUP_DIR.exists():
                    try:
                        BACKUP_DIR.mkdir(parents=True, exist_ok=True)
                        app.logger.info(f"åˆ›å»ºå¤‡ä»½ç›®å½•æˆåŠŸ: {BACKUP_DIR}")
                    except Exception as e:
                        app.logger.error(f"åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: {BACKUP_DIR}, é”™è¯¯: {str(e)}, æƒé™: {oct(BACKUP_DIR.parent.stat().st_mode)[-3:] if BACKUP_DIR.parent.exists() else 'N/A'}")
                        raise
                    
                # è·å–æ™®é€šå¤‡ä»½æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬permanentç›®å½•ï¼‰
                backups = sorted([
                    f for f in BACKUP_DIR.iterdir()
                    if f.name.startswith(file_path.name) and not f.is_dir()
                ], reverse=True)
                
                # åˆ é™¤æ—§å¤‡ä»½(ä¿ç•™6ä¸ªå†å²ç‰ˆæœ¬+å½“å‰ç‰ˆæœ¬)
                for old_backup in backups[6:]:
                    try:
                        old_backup.unlink()
                        app.logger.info(f"åˆ é™¤æ—§å¤‡ä»½æˆåŠŸ: {old_backup}")
                    except PermissionError:
                        app.logger.error(f"åˆ é™¤æ—§å¤‡ä»½å¤±è´¥(æƒé™ä¸è¶³): {old_backup}, æƒé™: {oct(old_backup.parent.stat().st_mode)[-3:] if old_backup.parent.exists() else 'N/A'}")
                        continue
                    except Exception as e:
                        app.logger.error(f"åˆ é™¤æ—§å¤‡ä»½å¤±è´¥: {old_backup}, é”™è¯¯: {str(e)}, æƒé™: {oct(old_backup.parent.stat().st_mode)[-3:] if old_backup.parent.exists() else 'N/A'}")
                        continue
                        
                # åˆ›å»ºæ–°å¤‡ä»½
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_path = BACKUP_DIR / f"{file_path.name}.{timestamp}"
                try:
                    shutil.copy2(file_path, backup_path)
                    app.logger.info(f"åˆ›å»ºæ–°å¤‡ä»½æˆåŠŸ: {file_path} -> {backup_path}")
                except Exception as e:
                    app.logger.error(f"åˆ›å»ºæ–°å¤‡ä»½å¤±è´¥: {file_path} -> {backup_path}, é”™è¯¯: {str(e)}, æƒé™: {oct(backup_path.parent.stat().st_mode)[-3:] if backup_path.parent.exists() else 'N/A'}")
                    raise
            except Exception as e:
                app.logger.error(f"å¤‡ä»½è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}, æ–‡ä»¶: {file_path}, å¤‡ä»½ç›®å½•: {BACKUP_DIR}, æƒé™: {oct(BACKUP_DIR.stat().st_mode)[-3:] if BACKUP_DIR.exists() else 'N/A'}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­ä¿å­˜æ“ä½œ
                return jsonify({
                    'status': 'warning',
                    'message': 'æ–‡ä»¶å·²ä¿å­˜ï¼Œä½†å¤‡ä»½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå¯èƒ½æ— æ³•åˆ›å»ºæ–°çš„å¤‡ä»½ã€‚ï¼ˆé‡å¯ä¸€ä¸‹ç”µè„‘ä¹Ÿè®¸å°±è§£å†³äº†ï¼ˆ'
                })

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            app.logger.info(f"ä¿å­˜æ–‡ä»¶æˆåŠŸ: {file_path}")
            return jsonify({'status': 'success'})
        except Exception as e:
            app.logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}, æƒé™: {oct(file_path.parent.stat().st_mode)[-3:] if file_path.parent.exists() else 'N/A'}")
            return jsonify({'status': 'error', 'message': str(e)})
    except Exception as e:
        app.logger.error(f"å¤„ç†ä¿å­˜è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})


def find_related_json(lyrics_path):
    """æŸ¥æ‰¾å¼•ç”¨è¯¥æ­Œè¯æ–‡ä»¶çš„JSONæ–‡ä»¶"""
    related_jsons = []
    static_dir = BASE_PATH / 'static'
    lyrics_path = Path(lyrics_path)
    
    # ç¡®ä¿æ­Œè¯è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
    if not lyrics_path.is_absolute():
        app.logger.warning(f"æ­Œè¯è·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„: {lyrics_path}")
        return related_jsons
        
    # è·å–æ­Œè¯æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ï¼ˆç”¨äºåŒ¹é…ï¼‰
    try:
        lyrics_relative = lyrics_path.relative_to(SONGS_DIR)
    except ValueError:
        app.logger.warning(f"æ­Œè¯æ–‡ä»¶ä¸åœ¨songsç›®å½•ä¸­: {lyrics_path}")
        return related_jsons

    for json_file in static_dir.iterdir():
        if json_file.suffix == '.json':
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    lyrics_fields = data['meta'].get('lyrics', '').split('::')
                    # æ£€æŸ¥æ¯ä¸ªå­—æ®µæ˜¯å¦åŒ…å«å½“å‰æ­Œè¯æ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                    if any(str(lyrics_relative) in field for field in lyrics_fields):
                        related_jsons.append(str(json_file))
            except Exception as e:
                app.logger.warning(f"å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™ {json_file}: {str(e)}")
                continue
    return related_jsons


@app.route('/update_file_path', methods=['POST'])
def update_file_path():
    if not is_request_allowed():
        return abort(403)
    data = request.json
    json_path = BASE_PATH / 'static' / data['jsonFile']
    file_type = data['fileType']
    new_path = data['newPath']

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)

        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        if not BACKUP_DIR.exists():
            BACKUP_DIR.mkdir(parents=True, exist_ok=True)

        # å¤‡ä»½åŸæ–‡ä»¶
        timestamp = int(time.time())
        backup_path = BACKUP_DIR / f"{data['jsonFile']}.{timestamp}"
        if json_path.exists():  # åªåœ¨æ–‡ä»¶å­˜åœ¨æ—¶è¿›è¡Œå¤‡ä»½
            shutil.copy2(json_path, backup_path)

        # æ›´æ–°è·¯å¾„
        if file_type == 'music':
            json_data['song'] = f"http://127.0.0.1:5000/songs/{new_path}"
        elif file_type == 'image':
            json_data['meta'][
                'albumImgSrc'] = f"http://127.0.0.1:5000/songs/{new_path}"
        elif file_type == 'background':
            json_data['meta']['Background-image'] = f"./songs/{new_path}"
        elif file_type == 'lyrics':
            current_lyrics = json_data['meta']['lyrics'].split('::')
            if len(current_lyrics) >= 4:
                if data.get('index') == 0:  # æ­Œè¯æ–‡ä»¶
                    new_lyrics_path = f"http://127.0.0.1:5000/songs/{new_path}" if new_path else '!'
                    current_lyrics[1] = new_lyrics_path
                elif data.get('index') == 1:  # æ­Œè¯ç¿»è¯‘
                    new_translation_path = f"http://127.0.0.1:5000/songs/{new_path}" if new_path else '!'
                    current_lyrics[2] = new_translation_path
                elif data.get('index') == 2:  # æ­Œè¯éŸ³è¯‘
                    new_transliteration_path = f"http://127.0.0.1:5000/songs/{new_path}" if new_path else '!'
                    current_lyrics[3] = new_transliteration_path
                json_data['meta']['lyrics'] = '::'.join(current_lyrics)

        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)

        # åœ¨æ›´æ–°è·¯å¾„åæ·»åŠ æ–‡ä»¶åˆ›å»ºé€»è¾‘
        new_local_path = SONGS_DIR / new_path
        if not new_local_path.parent.exists():
            new_local_path.parent.mkdir(parents=True, exist_ok=True)

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/create_json', methods=['POST'])
def create_json():
    if not is_request_allowed():
        return abort(403)
    data = request.json
    filename = data['filename']
    file_path = BASE_PATH / 'static' / filename

    try:
        if file_path.exists():
            return jsonify({'status': 'error', 'message': 'æ–‡ä»¶å·²å­˜åœ¨ï¼'})

        file_path.parent.mkdir(parents=True, exist_ok=True)
        print(f"åˆ›å»ºJSONæ–‡ä»¶: {file_path}")

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data['content'], f, ensure_ascii=False, indent=2)

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/rename_json', methods=['POST'])
def rename_json():
    if not is_request_allowed():
        return abort(403)
    data = request.json
    old_filename = data['oldFilename']
    new_filename = data['newFilename']
    title = data['title']
    artists = data['artists']

    old_path = BASE_PATH / 'static' / old_filename
    # æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢å…¨è§’å¼•å·
    new_filename = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', new_filename).replace('"', 'ï¼‚').replace("'", 'ï¼‚')
    new_path = BASE_PATH / 'static' / new_filename

    try:
        # æ£€æŸ¥æ–°æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
        if new_path.exists() and str(old_path).lower() != str(new_path).lower():
            return jsonify({'status': 'error', 'message': 'æ–‡ä»¶åå·²å­˜åœ¨ï¼'})

        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        if not BACKUP_DIR.exists():
            BACKUP_DIR.mkdir(parents=True, exist_ok=True)

        # è¯»å–åŸæ–‡ä»¶å†…å®¹
        with open(old_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)

        # å¤‡ä»½åŸæ–‡ä»¶
        timestamp = int(time.time())
        backup_path = BACKUP_DIR / f"{old_filename}.{timestamp}"
        shutil.copy2(old_path, backup_path)

        # æ›´æ–°JSONå†…å®¹
        json_data['meta']['title'] = title
        json_data['meta']['artists'] = artists

        # å†™å…¥æ–°æ–‡ä»¶
        with open(new_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)

        # å¦‚æœæ–°æ—§æ–‡ä»¶åä¸åŒï¼Œåˆ é™¤æ—§æ–‡ä»¶
        if str(old_path).lower() != str(new_path).lower():
            old_path.unlink()

        return jsonify({'status': 'success'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/check_lyrics', methods=['POST'])
def check_lyrics():
    lyrics_path = request.json.get('path')
    real_path = Path(lyrics_path.replace('http://127.0.0.1:5000/songs/',
                                    str(SONGS_DIR) + '/'))

    try:
        with open(real_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯¹å”±æ ‡è®°
        has_duet = '[2]' in content or '[5]' in content or 'ttm:agent="v2"' in content

        # æ£€æŸ¥æ˜¯å¦åŒ…å«èƒŒæ™¯äººå£°æ ‡è®°
        has_background = '[6]' in content or '[7]' in content or '[8]' in content or 'ttm:role="x-bg"' in content

        return jsonify({
            'status': 'success',
            'hasDuet': has_duet,
            'hasBackgroundVocals': has_background
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/get_backups', methods=['POST'])
def get_backups():
    file_path = request.json.get('path').replace(
        'http://127.0.0.1:5000/songs/', str(SONGS_DIR) + '/')
    base_name = Path(file_path).name

    try:
        backups = []
        for f in BACKUP_DIR.iterdir():
            if f.name.startswith(base_name):
                timestamp = f.name.split('.')[-1]
                if len(timestamp) == 15 and timestamp.isdigit():
                    backups.append({
                        'path':
                        f"http://127.0.0.1:5000/backups/{f.name}",
                        'time':
                        f"{timestamp[0:4]}-{timestamp[4:6]}-{timestamp[6:8]} {timestamp[9:11]}:{timestamp[11:13]}:{timestamp[13:15]}"
                    })
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—å¹¶å–å‰7ä¸ª
        backups = sorted(backups, key=lambda x: x['time'], reverse=True)[:7]
        return jsonify({'status': 'success', 'backups': backups})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/upload_music', methods=['POST'])
def upload_music():
    if not is_request_allowed():
        return abort(403)
    try:
        if 'file' not in request.files:
            return jsonify({'status': 'error', 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # å…è®¸æ‰€æœ‰éŸ³é¢‘è§†é¢‘æ ¼å¼
        file_ext = Path(file.filename).suffix.lower()

        # æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢å…¨è§’å¼•å·
        clean_name = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', file.filename).replace('"', 'ï¼‚').replace("'", 'ï¼‚')
        save_path = SONGS_DIR / clean_name

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–
        file.save(save_path)

        return jsonify({'status': 'success', 'filename': clean_name})

    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/upload_image', methods=['POST'])
def upload_image():
    if not is_request_allowed():
        return abort(403)
    try:
        if 'file' not in request.files:
            return jsonify({'status': 'error', 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # éªŒè¯æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_extensions:
            return jsonify({
                'status': 'error',
                'message': 'åªæ”¯æŒ JPG/PNG/GIF/WEBP æ ¼å¼'
            })

        # æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢å…¨è§’å¼•å·
        clean_name = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', file.filename).replace('"', 'ï¼‚').replace("'", 'ï¼‚')
        save_path = SONGS_DIR / clean_name

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–
        file.save(save_path)

        return jsonify({'status': 'success', 'filename': clean_name})

    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/upload_lyrics', methods=['POST'])
def upload_lyrics():
    if not is_request_allowed():
        return abort(403)
    client_ip = request.remote_addr
    user_agent = request.headers.get('User-Agent', 'Unknown')
    username = "Anonymous"  # å¯æ ¹æ®å®é™…ç™»å½•ç³»ç»Ÿæ›¿æ¢

    try:
        if 'file' not in request.files:
            app.logger.error(
                f'[{client_ip}] {username} ä¸Šä¼ å¤±è´¥: æœªé€‰æ‹©æ–‡ä»¶ | UA: {user_agent}')
            return jsonify({'status': 'error', 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            app.logger.error(
                f'[{client_ip}] {username} ä¸Šä¼ å¤±è´¥: ç©ºæ–‡ä»¶å | UA: {user_agent}')
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # éªŒè¯æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.lrc', '.lys', '.ttml'}
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_extensions:
            app.logger.warning(
                f'[{client_ip}] {username} å°è¯•ä¸Šä¼ éæ³•ç±»å‹: {file_ext} | æ–‡ä»¶å: {file.filename}'
            )
            return jsonify({'status': 'error', 'message': 'åªæ”¯æŒ LRC/LYS/ttml æ ¼å¼'})

        # æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢å…¨è§’å¼•å·
        clean_name = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', file.filename).replace('"', 'ï¼‚').replace("'", 'ï¼‚')
        save_path = SONGS_DIR / clean_name

        # è®°å½•ä¸Šä¼ å¼€å§‹
        app.logger.info(
            f'[{client_ip}] {username} å¼€å§‹ä¸Šä¼ æ­Œè¯: {clean_name} | å¤§å°: {len(file.read())}å­—èŠ‚'
        )
        file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¦†ç›–
        file.save(save_path)

        # è·å–æ–‡ä»¶å…ƒä¿¡æ¯
        file_size = save_path.stat().st_size
        checksum = hashlib.md5(file.read()).hexdigest()
        file.seek(0)

        app.logger.info(
            f'[{client_ip}] {username} ä¸Šä¼ æˆåŠŸ: {clean_name} | å¤§å°: {file_size}å­—èŠ‚ | MD5: {checksum}'
        )

        return jsonify({'status': 'success', 'filename': clean_name})

    except Exception as e:
        error_msg = f'[{client_ip}] {username} ä¸Šä¼ å¤±è´¥: {str(e)} | æ–‡ä»¶: {file.filename}'
        app.logger.error(error_msg, exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)})


@app.route('/upload_translation', methods=['POST'])
def upload_translation():
    if not is_request_allowed():
        return abort(403)
    client_ip = request.remote_addr
    user_agent = request.headers.get('User-Agent', 'Unknown')
    username = "Anonymous"

    try:
        if 'file' not in request.files:
            app.logger.error(
                f'[{client_ip}] {username} ç¿»è¯‘ä¸Šä¼ å¤±è´¥: æœªé€‰æ‹©æ–‡ä»¶ | UA: {user_agent}')
            return jsonify({'status': 'error', 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            app.logger.error(
                f'[{client_ip}] {username} ç¿»è¯‘ä¸Šä¼ å¤±è´¥: ç©ºæ–‡ä»¶å | UA: {user_agent}')
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # éªŒè¯æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.lrc', '.lys', '.ttml'}
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_extensions:
            app.logger.warning(
                f'[{client_ip}] {username} å°è¯•ä¸Šä¼ éæ³•ç¿»è¯‘ç±»å‹: {file_ext} | æ–‡ä»¶å: {file.filename}'
            )
            return jsonify({'status': 'error', 'message': 'åªæ”¯æŒ LRC/LYS/ttml æ ¼å¼'})

        # æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢å…¨è§’å¼•å·
        clean_name = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', file.filename).replace('"', 'ï¼‚').replace("'", 'ï¼‚')
        save_path = SONGS_DIR / clean_name

        # è®°å½•ä¸Šä¼ å¼€å§‹
        app.logger.info(
            f'[{client_ip}] {username} å¼€å§‹ä¸Šä¼ ç¿»è¯‘: {clean_name} | å¤§å°: {len(file.read())}å­—èŠ‚'
        )
        file.seek(0)

        # ä¿å­˜æ–‡ä»¶
        file.save(save_path)

        # è·å–æ–‡ä»¶å…ƒä¿¡æ¯
        file_size = save_path.stat().st_size
        checksum = hashlib.md5(file.read()).hexdigest()
        file.seek(0)

        app.logger.info(
            f'[{client_ip}] {username} ç¿»è¯‘ä¸Šä¼ æˆåŠŸ: {clean_name} | å¤§å°: {file_size}å­—èŠ‚ | MD5: {checksum}'
        )

        return jsonify({'status': 'success', 'filename': clean_name})

    except Exception as e:
        error_msg = f'[{client_ip}] {username} ç¿»è¯‘ä¸Šä¼ å¤±è´¥: {str(e)} | æ–‡ä»¶: {file.filename}'
        app.logger.error(error_msg, exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)})


# TTMLè½¬æ¢ç›¸å…³ç±»å’Œå‡½æ•°
class TTMLTime:
    _pattern: Pattern = compile(r'\d+')

    def __init__(self, centi: str = ''):
        if centi == '':
            # é»˜è®¤åˆå§‹åŒ–ä¸º 00:00.000ï¼Œé¿å…å±æ€§ç¼ºå¤±
            self._minute = 0
            self._second = 0
            self._micros = 0
            return
        # ä½¿ç”¨ finditer è·å–åŒ¹é…çš„è¿­ä»£å™¨
        matches: Iterator[Match[str]] = TTMLTime._pattern.finditer(centi)
        # è·å–ä¸‹ä¸€ä¸ªåŒ¹é…
        iterator: Iterator[Match[str]] = iter(matches)  # å°†åŒ¹é…å¯¹è±¡è½¬æ¢ä¸ºè¿­ä»£å™¨

        self._minute:int = int(next(iterator).group())
        self._second:int = int(next(iterator).group())
        self._micros:int = int(next(iterator).group())

    def __str__(self) -> str:
        return f'{self._minute:02}:{self._second:02}.{self._micros:03}'

    def __int__(self) -> int:
        return (self._minute * 60 + self._second) * 1000 + self._micros

    def __ge__(self, other) -> bool:
        return (self._minute, self._second, self._micros) >= (other._minute, other._second, other._micros)

    def __ne__(self, other) -> bool:
        return (self._minute, self._second, self._micros) != (other._minute, other._second, other._micros)

    def __sub__(self, other) -> int:
        return abs(int(self) - int(other))

class TTMLSyl:
    def __init__(self, element: Element):
        self.__element: Element = element
        self.__begin: TTMLTime = TTMLTime(element.getAttribute("begin"))
        self.__end: TTMLTime = TTMLTime(element.getAttribute("end"))

        # âœ… å®‰å…¨è®¿é—®å­èŠ‚ç‚¹æ–‡æœ¬
        node_val = None
        try:
            if element.childNodes and element.childNodes.length > 0:
                first = element.childNodes[0]
                # 3 = TEXT_NODE, 4 = CDATA_SECTION_NODE
                if getattr(first, "nodeType", None) in (3, 4):
                    node_val = first.nodeValue
        except Exception:
            node_val = None
        self.text: str = node_val or ""

    def __str__(self) -> str:
        return f'{self.text}({int(self.__begin)},{self.__end - self.__begin})'

    def get_begin(self) -> TTMLTime:
        return self.__begin

    # ğŸ‘‰ æ–°å¢ï¼š
    def get_end(self) -> TTMLTime:
        return self.__end

class TTMLLine:
    have_ts: bool = False
    have_duet: bool = False
    have_bg: bool = False
    have_pair: int = 0

    __before: Pattern[AnyStr] = compile(r'^\({2,}')
    __after: Pattern[AnyStr] = compile(r'\){2,}$')

    def __init__(self, element: Element, is_bg: bool = False):
        self.__element: Element = element
        self.__orig_line = []  # å¯ä»¥åŒ…å«TTMLSylæˆ–strç±»å‹
        self.__ts_line = None  # å¯ä»¥æ˜¯stræˆ–None
        self.__bg_line = None  # å¯ä»¥æ˜¯TTMLLineæˆ–None
        self.__is_bg: bool = is_bg

        TTMLLine.have_bg |= is_bg

        # è·å–ä¼ å…¥å…ƒç´ çš„ agent å±æ€§
        agent = element.getAttribute("ttm:agent")
        self.__is_duet:bool = bool(agent and agent != 'v1')

        # è·å– <p> å…ƒç´ çš„æ‰€æœ‰å­èŠ‚ç‚¹ï¼ŒåŒ…æ‹¬æ–‡æœ¬èŠ‚ç‚¹
        child_elements = element.childNodes  # iter() ä¼šè¿”å›æ‰€æœ‰å­å…ƒç´ å’Œæ–‡æœ¬èŠ‚ç‚¹

        # éå†æ‰€æœ‰å­èŠ‚ç‚¹
        for child in child_elements:
            # TEXT_NODE
            if getattr(child, "nodeType", None) == 3 and getattr(child, "nodeValue", None) is not None:
                # åˆå¹¶æçŸ­çš„ç©ºç™½åˆ°ä¸Šä¸€ syl
                if len(self.__orig_line) > 0 and len(child.nodeValue) < 2:
                    try:
                        last = self.__orig_line[-1]
                        if isinstance(last, TTMLSyl):
                            last.text = (last.text or "") + child.nodeValue
                        elif isinstance(last, str):
                            self.__orig_line[-1] = last + child.nodeValue
                    except Exception:
                        pass
                else:
                    self.__orig_line.append(child.nodeValue)
                continue

            # åªå¤„ç† ELEMENT_NODE
            if getattr(child, "nodeType", None) != 1:
                continue

            role = child.getAttribute("ttm:role") if child.hasAttribute("ttm:role") else ""

            if role == "":
                # æ™®é€š syllableï¼šå¿…é¡»æœ‰æ–‡æœ¬å­èŠ‚ç‚¹
                if child.childNodes and child.childNodes.length > 0:
                    try:
                        # TTMLSyl å†…éƒ¨ä¹Ÿåšäº†åˆ¤ç©º
                        self.__orig_line.append(TTMLSyl(child))
                    except Exception as e:
                        app.logger.debug(f"TTMLSyl æ„é€ è·³è¿‡ç©ºèŠ‚ç‚¹: {e!r}")
                continue

            if role == "x-bg":
                self.__bg_line = TTMLLine(child, True)
                self.__bg_line.__is_duet = self.__is_duet
                continue

            if role == "x-translation":
                TTMLLine.have_ts = True
                try:
                    if child.childNodes and child.childNodes.length > 0:
                        first = child.childNodes[0]
                        if getattr(first, "nodeType", None) in (3, 4) and first.nodeValue:
                            self.__ts_line = f'{first.nodeValue}'
                except Exception as e:
                    app.logger.debug(f"ç¿»è¯‘è¡Œè§£æå¤±è´¥ï¼š{e!r}")
                continue

        # âœ… æ­£ç¡®è®¾ç½®æœ¬è¡Œ begin/end
        if self.__orig_line and isinstance(self.__orig_line[0], TTMLSyl):
            self.__begin = self.__orig_line[0].get_begin()
            # å–è¯¥è¡Œæœ€åä¸€ä¸ª syl çš„ end æ›´ç¨³å¦¥
            last_syl = next((x for x in reversed(self.__orig_line) if isinstance(x, TTMLSyl)), None)
            self.__end = last_syl.get_end() if last_syl else self.__begin
        else:
            # çº¯æ–‡æœ¬ pï¼šç›´æ¥è¯» p çš„å±æ€§
            self.__begin = TTMLTime(element.getAttribute("begin"))
            self.__end   = TTMLTime(element.getAttribute("end"))
            if not self.__orig_line:
                self.__orig_line.append('')

        if is_bg and self.__orig_line and isinstance(self.__orig_line[0], TTMLSyl):
            if TTMLLine.__before.search(self.__orig_line[0].text):
                self.__orig_line[0].text = TTMLLine.__before.sub('(', self.__orig_line[0].text)
                TTMLLine.have_pair += 1
            if TTMLLine.__after.search(self.__orig_line[-1].text):
                self.__orig_line[-1].text = TTMLLine.__after.sub(')', self.__orig_line[-1].text)
                TTMLLine.have_pair += 1

    def __role(self) -> int:
        return ((int(TTMLLine.have_bg) + int(self.__is_bg)) * 3
                + int(TTMLLine.have_duet) + int(self.__is_duet))

    def __raw(self):
        try:
            filtered_line = []
            has_syl = False
            for v in self.__orig_line:
                if isinstance(v, str):
                    if v.strip():
                        filtered_line.append(v)
                else:
                    has_syl = True
                    filtered_line.append(v)

            line_text = ''.join([str(v) for v in filtered_line]) if filtered_line else ''

            # ğŸ‘‰ çº¯æ–‡æœ¬è¡Œï¼šè¡¥ä¸Š (begin,duration)
            if not has_syl and line_text:
                duration_ms = self.__end - self.__begin
                line_text = f"{line_text}({int(self.__begin)},{duration_ms})"

            main_line = f'[{self.__role()}]{line_text}'
            translation_line = None
            if not self.__is_bg and self.__ts_line:
                translation_line = f'[{self.__begin}]{self.__ts_line}'
            return (main_line, translation_line)
        except Exception as e:
            app.logger.error(f"ç”Ÿæˆæ­Œè¯è¡Œæ—¶å‡ºé”™: {str(e)}")
            return (f'[{self.__role()}]é”™è¯¯çš„è¡Œ', None)

    def to_str(self):
        # è¿”å›å…ƒç»„(å…ƒç»„(str, stræˆ–None), å…ƒç»„(str, stræˆ–None)æˆ–None)
        return self.__raw(), (self.__bg_line.__raw() if self.__bg_line else None)

def ttml_to_lys(input_path, songs_dir):
    """ä¸»è½¬æ¢å‡½æ•°"""
    TTMLLine.have_duet = False
    TTMLLine.have_bg = False
    TTMLLine.have_ts = False
    TTMLLine.have_pair = 0

    lyric_path = ''
    trans_path = ''
    try:
        # è§£æXMLæ–‡ä»¶
        dom: Document = xml.dom.minidom.parse(input_path)
        tt: Document = dom.documentElement  # è·å–æ ¹å…ƒç´ 

        # è·å–ttä¸­çš„body/headå…ƒç´ 
        body_elements = tt.getElementsByTagName('body')
        head_elements = tt.getElementsByTagName('head')
        
        if not body_elements or not head_elements:
            app.logger.error(f"TTMLæ–‡ä»¶æ ¼å¼é”™è¯¯: {input_path}. æ‰¾ä¸åˆ°å¿…è¦çš„bodyæˆ–headå…ƒç´ ")
            return False, None, None
            
        body: Element = body_elements[0]
        head: Element = head_elements[0]

        if body and head:
            # è·å–body/headä¸­çš„<div>/<metadata>å­å…ƒç´ 
            div_elements = body.getElementsByTagName('div')
            metadata_elements = head.getElementsByTagName('metadata')
            
            if not div_elements or not metadata_elements:
                app.logger.error(f"TTMLæ–‡ä»¶æ ¼å¼é”™è¯¯: {input_path}. æ‰¾ä¸åˆ°å¿…è¦çš„divæˆ–metadataå…ƒç´ ")
                return False, None, None
                
            div: Element = div_elements[0]
            metadata: Element = metadata_elements[0]

            # è·å–divä¸­çš„æ‰€æœ‰<p>å­å…ƒç´ 
            p_elements: NodeList[Element] = div.getElementsByTagName('p')
            if not p_elements or len(p_elements) == 0:
                app.logger.error(f"TTMLæ–‡ä»¶æ ¼å¼é”™è¯¯: {input_path}. æ‰¾ä¸åˆ°ä»»ä½•på…ƒç´ ")
                return False, None, None
                
            agent_elements: NodeList[Element] = metadata.getElementsByTagName('ttm:agent')

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹å”±
            for meta in agent_elements:
                if meta.getAttribute('xml:id') != 'v1':
                    TTMLLine.have_duet = True

            lines: list[TTMLLine] = []
            # éå†æ¯ä¸ª<p>å…ƒç´ 
            for p in p_elements:
                try:
                    lines.append(TTMLLine(p))
                except Exception as e:
                    app.logger.error(f"å¤„ç†TTMLè¡Œæ—¶å‡ºé”™: {type(e).__name__}: {e!s}ï¼Œå·²è·³è¿‡")
                    continue
            
            # ç¡®ä¿songsç›®å½•å­˜åœ¨
            os.makedirs(songs_dir, exist_ok=True)

            # ä¿®æ”¹è·¯å¾„
            base_name = os.path.splitext(input_path)[0]

            lyric_file: TextIO|None = None
            trans_file: TextIO|None = None

            lyric_path = os.path.join(songs_dir, f"{os.path.basename(base_name)}.lys")
            lyric_file = open(lyric_path, 'w', encoding='utf8')

            if TTMLLine.have_ts:
                trans_path = os.path.join(songs_dir, f"{os.path.basename(base_name)}_trans.lrc")
                trans_file = open(trans_path, 'w', encoding='utf8')

            count: int = 0

            try:
                for main_line, bg_line in [line.to_str() for line in lines]:
                    if main_line and main_line[0]:
                        lyric_file.write(main_line[0] + '\n')
                        lyric_file.flush()
                    if main_line and main_line[1] and trans_file:
                        trans_file.write(main_line[1] + '\n')
                        trans_file.flush()

                    if bg_line:
                        if bg_line[0]:
                            lyric_file.write(bg_line[0] + '\n')
                            lyric_file.flush()
                        # èƒŒæ™¯æ­Œè¯ä¸ç”Ÿæˆç‹¬ç«‹çš„ç¿»è¯‘è¡Œï¼Œå› ä¸ºå®ƒåº”è¯¥ä¸ä¸»æ­Œè¯å…±äº«ç¿»è¯‘
                        count += 1
            except Exception as e:
                app.logger.error(f"å†™å…¥æ­Œè¯æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            finally:
                # ç¡®ä¿æ–‡ä»¶å§‹ç»ˆè¢«å…³é—­
                if lyric_file:
                    lyric_file.close()
                if trans_file:
                    trans_file.close()

        else:
            return False, None, None

    except Exception as e:
        app.logger.error(f"æ— æ³•è§£æTTMLæ–‡ä»¶: {input_path}. é”™è¯¯: {str(e)}")
        return False, None, None

    return True, lyric_path, trans_path

def preprocess_brackets(content):
    """
    é¢„å¤„ç†ç‰¹æ®Šæ‹¬å·æ¨¡å¼ï¼ŒæŒ‰ç…§ç”¨æˆ·å»ºè®®å¤„ç†ï¼š
    "((" â†’ åˆ é™¤ç¬¬ä¸€ä¸ª"("ï¼Œä¿ç•™ç¬¬äºŒä¸ª"("ï¼Œç»“æœä¸º"("
    ")(" â†’ åˆ é™¤")"ï¼Œä¿ç•™"("ï¼Œç»“æœä¸º"("
    åŒæ—¶å¤„ç†æ›´å¤æ‚çš„åµŒå¥—æƒ…å†µ
    """
    # å¤„ç† "((" æ¨¡å¼
    content = re.sub(r'\(\(', '(', content)
    # å¤„ç† ")(" æ¨¡å¼
    content = re.sub(r'\)\(', '(', content)
    return content


def parse_syllable_info(content, marker='', offset=0):
    """è§£æLYSå†…å®¹ä¸­çš„éŸ³èŠ‚ä¿¡æ¯ï¼Œè¿”å›éŸ³èŠ‚åˆ—è¡¨ï¼›offset ä¸ºæ¯«ç§’ï¼Œæ­£è´Ÿçš†å¯ã€‚"""
    content = preprocess_brackets(content)
    syllables = []

    if marker in ['6', '7', '8']:
        pattern = r'\(([^()]+?)\)\((\d+),(\d+)\)'
        matches = re.finditer(pattern, content)
        for match in matches:
            text_part = match.group(1)
            start_ms = int(match.group(2))
            duration_ms = int(match.group(3))
            start_ms += offset  # åº”ç”¨ offset
            syllables.append({
                'text': text_part,
                'start_ms': start_ms,
                'duration_ms': duration_ms
            })

    if not syllables:
        pattern = r'([^()]*?)\((\d+),(\d+)\)'
        matches = re.finditer(pattern, content)
        for match in matches:
            text_part = match.group(1)
            start_ms = int(match.group(2))
            duration_ms = int(match.group(3))
            start_ms += offset  # åº”ç”¨ offset
            syllables.append({
                'text': text_part,
                'start_ms': start_ms,
                'duration_ms': duration_ms
            })

    if not syllables:
        line_match = re.search(r'^(.*)\((\d+),(\d+)\)$', content)
        if line_match:
            text = line_match.group(1)
            start_ms = int(line_match.group(2))
            duration_ms = int(line_match.group(3))
            start_ms += offset  # åº”ç”¨ offset
            if text or start_ms > 0 or duration_ms > 0:
                syllables.append({
                    'text': text,
                    'start_ms': start_ms,
                    'duration_ms': duration_ms
                })

    return syllables


def ms_to_ttml_time(ms):
    """å°†æ¯«ç§’è½¬æ¢ä¸ºTTMLæ—¶é—´æ ¼å¼ï¼ˆAppleé£æ ¼ï¼‰"""
    total_seconds = ms / 1000.0
    ms_part = int(round((total_seconds - int(total_seconds)) * 1000))
    s_part = int(total_seconds) % 60
    m_part = int(total_seconds) // 60

    # <60s ç”¨ s.mmmï¼›>=60s ç”¨ m:ss.mmm
    if m_part == 0:
        if ms_part == 0 and total_seconds == int(total_seconds):
            return str(int(total_seconds))
        else:
            return f"{int(total_seconds)}.{ms_part:03d}"
    else:
        return f"{m_part}:{s_part:02d}.{ms_part:03d}"


def _nearest_translation(begin_ms, trans_map, tol_ms=300):
    """
    åœ¨ translation dict é‡Œæ‰¾ä¸ begin_ms æœ€æ¥è¿‘çš„é”®ï¼ˆå®¹å·® Â±tol_msï¼‰ã€‚
    å‘½ä¸­åä»å­—å…¸ä¸­ç§»é™¤è¯¥é”®ï¼Œé¿å…é‡å¤åŒ¹é…ã€‚
    """
    if not trans_map:
        return None
    # å…ˆè¯•ç²¾ç¡®å‘½ä¸­
    if begin_ms in trans_map:
        return trans_map.pop(begin_ms)
    # æ‰¾æœ€è¿‘
    nearest_key = min(trans_map.keys(), key=lambda k: abs(k - begin_ms))
    if abs(nearest_key - begin_ms) <= tol_ms:
        return trans_map.pop(nearest_key)
    return None


def ttml_time_to_ms(time_str):
    """å°†TTMLæ—¶é—´æ ¼å¼è½¬æ¢ä¸ºæ¯«ç§’ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
    if not time_str:
        return 0

    time_str = time_str.strip()

    # H:MM:SS.mmm æ ¼å¼
    m = re.match(r"^(?:(\d+):)?(\d{1,2}):(\d{1,2}(?:\.\d{1,3})?)$", time_str)
    if m:
        h = int(m.group(1) or 0)
        mm = int(m.group(2))
        ss = float(m.group(3))
        return int((h*3600 + mm*60 + ss) * 1000)

    # MM:SS.mmm æ ¼å¼
    m = re.match(r"^(\d{1,2}):(\d{1,2}(?:\.\d{1,3})?)$", time_str)
    if m:
        mm = int(m.group(1))
        ss = float(m.group(2))
        return int((mm*60 + ss) * 1000)

    # SS.mmm æ ¼å¼
    try:
        sec = float(time_str)
        return int(sec * 1000)
    except ValueError:
        return 0




def text_tail_space(txt):
    """è¿”å› (æ¸…ç†åçš„æ–‡æœ¬, æ˜¯å¦æœ«å°¾æœ‰ç©ºæ ¼)"""
    if txt is None:
        return "", False
    has_space = len(txt) > 0 and txt[-1].isspace()
    return txt.rstrip(), has_space


def find_translation_file(lyrics_path):
    """æŸ¥æ‰¾å…³è”çš„ç¿»è¯‘æ–‡ä»¶"""
    lyrics_path = Path(lyrics_path)
    # å°è¯•æŸ¥æ‰¾åŒåä½†å¸¦æœ‰_transåç¼€çš„LRCæ–‡ä»¶
    trans_path = lyrics_path.parent / f"{lyrics_path.stem}_trans.lrc"
    if trans_path.exists():
        return str(trans_path)

    # å°è¯•æŸ¥æ‰¾åŒç›®å½•ä¸‹çš„LRCæ–‡ä»¶ï¼ˆä¸å¸¦_transåç¼€ï¼‰
    lrc_files = list(lyrics_path.parent.glob("*.lrc"))
    for lrc_file in lrc_files:
        if lrc_file.name != lyrics_path.name and lrc_file.name.startswith(lyrics_path.stem):
            return str(lrc_file)

    return None


def lys_to_ttml(input_path, output_path):
    """å°†LYSæ ¼å¼è½¬æ¢ä¸ºTTMLæ ¼å¼ï¼ˆAppleé£æ ¼ï¼‰"""
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            lys_content = f.read()

        # ---- æå– offsetï¼ˆæ¯«ç§’ï¼‰ ----
        offset = 0
        offset_match = re.search(r'\[offset:\s*(-?\d+)\s*\]', lys_content)
        if offset_match:
            try:
                offset = int(offset_match.group(1))
            except Exception:
                offset = 0

        # ---- è¯»å–å¹¶è§£æç¿»è¯‘ LRCï¼šè½¬æˆ æ¯«ç§’â†’æ–‡æœ¬ çš„å­—å…¸ï¼Œä¾›"å®¹å·®åŒ¹é…" ----
        trans_path = find_translation_file(input_path)
        translation_dict_ms = {}
        trans_offset = 0
        if trans_path:
            try:
                with open(trans_path, 'r', encoding='utf-8') as f:
                    trans_content = f.read()

                # æå–ç¿»è¯‘æ–‡ä»¶è‡ªèº«çš„ offsetï¼ˆæ¯«ç§’ï¼‰
                trans_offset_match = re.search(r'\[offset:\s*(-?\d+)\s*\]', trans_content)
                if trans_offset_match:
                    try:
                        trans_offset = int(trans_offset_match.group(1))
                    except Exception:
                        trans_offset = 0

                trans_lines = [line.strip() for line in trans_content.split('\n') if line.strip()]
                for line in trans_lines:
                    begin_time_str, content = parse_lrc_line(line)  # "mm:ss.mmm"
                    if begin_time_str and content is not None:
                        begin_ms = ttml_time_to_ms(begin_time_str)
                        # ç»™ç¿»è¯‘æ—¶é—´å åŠ ç¿»è¯‘æ–‡ä»¶è‡ªèº«çš„ offset
                        begin_ms += trans_offset
                        translation_dict_ms[begin_ms] = content
            except Exception as e:
                app.logger.warning(f"è¯»å–ç¿»è¯‘æ–‡ä»¶æ—¶å‡ºé”™: {trans_path}. é”™è¯¯: {str(e)}")

        # ---- è§£æ LYS ä¸»ä½“ ----
        lines = [line.strip() for line in lys_content.split('\n') if line.strip()]
        parsed_lines = []

        for i, line in enumerate(lines):
            # è·³è¿‡å…ƒæ•°æ®
            if line.startswith('[from:') or line.startswith('[id:') or line.startswith('[offset:'):
                continue

            m_line = re.match(r'\[([^\]]*)\](.*)', line)
            if not m_line:
                continue

            marker = m_line.group(1)       # å¯èƒ½ä¸ºç©º
            content = m_line.group(2)

            # è§£æéŸ³èŠ‚ + åº”ç”¨ offset
            syllables = parse_syllable_info(content, marker, offset=offset)

            if syllables:
                begin_time_ms = syllables[0]['start_ms']
                # ç»™ç¿»è¯‘æ—¶é—´ä¹Ÿå åŠ  LYS çš„ offsetï¼ˆä¸æ­Œè¯åŒæ­¥ï¼‰
                begin_time_ms_with_offset = begin_time_ms + offset
                # ä½¿ç”¨å®¹å·®åŒ¹é…ï¼ˆÂ±300msï¼‰æ‰¾æœ€æ¥è¿‘çš„ç¿»è¯‘
                translation_content = _nearest_translation(begin_time_ms_with_offset, translation_dict_ms, 300)

                parsed_lines.append({
                    'marker': marker,
                    'content': content,
                    'syllables': syllables,
                    'is_duet': marker in ['2', '5'],
                    'is_background': marker in ['6', '7', '8'],
                    'translation': translation_content
                })

        # ---- ç»Ÿè®¡æ—¶é•¿èŒƒå›´ ----
        has_duet = any(line['is_duet'] for line in parsed_lines)
        dom, div = create_ttml_document(has_duet)

        first_begin = None
        last_end = 0
        for line_info in parsed_lines:
            s = line_info['syllables']
            if not s:
                continue
            b_ms = s[0]['start_ms']
            e_ms = s[-1]['start_ms'] + s[-1]['duration_ms']
            if first_begin is None:
                first_begin = b_ms
            if e_ms > last_end:
                last_end = e_ms

        body_elements = dom.getElementsByTagName('body')
        if body_elements:
            body = body_elements[0]
            body.setAttribute('dur', ms_to_ttml_time(last_end))

        if first_begin is not None:
            div.setAttribute('begin', ms_to_ttml_time(first_begin))
            div.setAttribute('end',   ms_to_ttml_time(last_end))

        # ---- å†™å…¥æ¯ä¸€è¡Œ ----
        key_idx = 1
        prev_main_p = None

        for line_info in parsed_lines:
            s = line_info['syllables']
            if not s:
                continue

            begin_ms = s[0]['start_ms']
            end_ms   = s[-1]['start_ms'] + s[-1]['duration_ms']
            begin = ms_to_ttml_time(begin_ms)
            end   = ms_to_ttml_time(end_ms)

            if not line_info['is_background']:
                p = dom.createElement('p')
                p.setAttribute('begin', begin)
                p.setAttribute('end', end)
                p.setAttribute('itunes:key', f'L{key_idx}')
                p.setAttribute('ttm:agent', 'v1' if not line_info['is_duet'] else 'v2')
                key_idx += 1

                # é€éŸ³èŠ‚ spanï¼ˆApple é£æ ¼ï¼‰
                for syl in s:
                    text = syl['text']
                    if text is not None:
                        span = dom.createElement('span')
                        span.setAttribute('begin', ms_to_ttml_time(syl['start_ms']))
                        span.setAttribute('end',   ms_to_ttml_time(syl['start_ms'] + syl['duration_ms']))
                        txt, tail = text_tail_space(text)
                        span.appendChild(dom.createTextNode(txt))
                        if tail:
                            span.appendChild(dom.createTextNode(' '))
                        p.appendChild(span)

                # æœ‰ç¿»è¯‘å°±åŠ ç¿»è¯‘ spanï¼›æ²¡æœ‰å°±ä¸åŠ ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
                if line_info.get('translation'):
                    trans_span = dom.createElement('span')
                    trans_span.setAttribute('ttm:role', 'x-translation')
                    trans_span.setAttribute('xml:lang', 'zh-CN')
                    trans_span.appendChild(dom.createTextNode(line_info['translation']))
                    p.appendChild(trans_span)

                div.appendChild(p)
                prev_main_p = p
            else:
                # èƒŒæ™¯è¡Œï¼šå¡åˆ°ä¸Šä¸€ä¸»è¡Œ <span ttm:role="x-bg">
                if prev_main_p is None:
                    p = dom.createElement('p')
                    p.setAttribute('begin', begin)
                    p.setAttribute('end', end)
                    p.setAttribute('itunes:key', f'L{key_idx}')
                    p.setAttribute('ttm:agent', 'v1')
                    key_idx += 1
                    div.appendChild(p)
                    prev_main_p = p

                bg_span = dom.createElement('span')
                bg_span.setAttribute('ttm:role', 'x-bg')
                bg_span.setAttribute('begin', begin)
                bg_span.setAttribute('end', end)

                for syl in s:
                    text = syl['text']
                    if text is not None:
                        span = dom.createElement('span')
                        span.setAttribute('begin', ms_to_ttml_time(syl['start_ms']))
                        span.setAttribute('end',   ms_to_ttml_time(syl['start_ms'] + syl['duration_ms']))
                        txt, tail = text_tail_space(text)
                        span.appendChild(dom.createTextNode(txt))
                        if tail:
                            span.appendChild(dom.createTextNode(' '))
                        bg_span.appendChild(span)

                # èƒŒæ™¯è¡Œçš„ç¿»è¯‘ï¼ˆå¦‚æœè¿™ä¸€è¡Œä¹Ÿåˆšå¥½æœ‰å¯¹åº”æ—¶é—´ç¿»è¯‘ï¼‰
                if line_info.get('translation'):
                    trans_span = dom.createElement('span')
                    trans_span.setAttribute('ttm:role', 'x-translation')
                    trans_span.setAttribute('xml:lang', 'zh-CN')
                    trans_span.appendChild(dom.createTextNode(line_info['translation']))
                    bg_span.appendChild(trans_span)

                prev_main_p.appendChild(bg_span)

        # å•è¡Œè¾“å‡º
        with open(output_path, 'w', encoding='utf-8') as f:
            dom.writexml(f, indent='', addindent='', newl='', encoding='utf-8')

        return True, None

    except Exception as e:
        app.logger.error(f"æ— æ³•è½¬æ¢LYSåˆ°TTML: {input_path}. é”™è¯¯: {str(e)}")
        return False, str(e)

def create_ttml_document(has_duet=False):
    """åˆ›å»ºTTMLæ–‡æ¡£åŸºç¡€ç»“æ„ï¼ˆAppleé£æ ¼ï¼‰"""
    # åˆ›å»ºTTMLæ–‡æ¡£
    dom = xml.dom.minidom.Document()

    # åˆ›å»ºæ ¹å…ƒç´ ttï¼ˆæ·»åŠ Appleé£æ ¼çš„å‘½åç©ºé—´ï¼‰
    tt = dom.createElement('tt')
    tt.setAttribute('xmlns', 'http://www.w3.org/ns/ttml')
    tt.setAttribute('xmlns:ttm', 'http://www.w3.org/ns/ttml#metadata')
    tt.setAttribute('xmlns:itunes', 'http://music.apple.com/lyric-ttml-internal')
    tt.setAttribute('xmlns:amll', 'http://www.example.com/ns/amll')
    tt.setAttribute('itunes:timing', 'Word')
    tt.setAttribute('xml:space', 'preserve')  # ä¿ç•™ç©ºç™½å­—ç¬¦
    dom.appendChild(tt)

    # åˆ›å»ºheadå…ƒç´ 
    head = dom.createElement('head')
    tt.appendChild(head)

    # åˆ›å»ºmetadataå…ƒç´ 
    metadata = dom.createElement('metadata')
    head.appendChild(metadata)

    # åˆ›å»ºagentå…ƒç´ 
    agent1 = dom.createElement('ttm:agent')
    agent1.setAttribute('type', 'person')
    agent1.setAttribute('xml:id', 'v1')
    metadata.appendChild(agent1)

    # åˆ›å»ºèƒŒæ™¯äººå£°agent
    agent2 = dom.createElement('ttm:agent')
    agent2.setAttribute('type', 'other')
    agent2.setAttribute('xml:id', 'v2')
    metadata.appendChild(agent2)

    # åˆ›å»ºstylingå…ƒç´ ï¼ˆä¿æŒä½†å¯ä»¥ä¸ºç©ºï¼‰
    styling = dom.createElement('styling')
    head.appendChild(styling)

    # åˆ›å»ºbodyå…ƒç´ 
    body = dom.createElement('body')
    body.setAttribute('xml:space', 'preserve')  # ä¿ç•™ç©ºç™½å­—ç¬¦
    tt.appendChild(body)

    # åˆ›å»ºdivå…ƒç´ 
    div = dom.createElement('div')
    div.setAttribute('xml:space', 'preserve')  # ä¿ç•™ç©ºç™½å­—ç¬¦
    body.appendChild(div)

    return dom, div


def parse_lrc_line(line):
    """è§£æLRCè¡Œï¼Œè¿”å›æ—¶é—´æˆ³å’Œå†…å®¹"""
    time_match = re.match(r'\[(\d{2}):(\d{2})\.(\d{2,3})\](.*)', line)
    if time_match:
        min, sec, ms, content = time_match.groups()
        # ç¡®ä¿æ¯«ç§’æ˜¯3ä½æ•°
        if len(ms) == 2:
            ms = ms + '0'
        begin_time = f"{min}:{sec}.{ms}"
        # åªå»é™¤æœ«å°¾çš„å›è½¦ï¼Œä¿ç•™æ‰€æœ‰ç©ºæ ¼
        return begin_time, content.rstrip('\r')
    return None, None


def _extract_lrc_marker_and_clean(content):
    """æå–LRCè¡Œçš„æ ‡è®°å¹¶æ¸…ç†å†…å®¹"""
    # åŒ¹é…è¡Œé¦–çš„æ ‡è®°ï¼Œå¦‚ [6]content
    marker_match = re.match(r'^\[(\d+)\](.*)', content)
    if marker_match:
        marker = marker_match.group(1)
        # ä¿ç•™ç©ºæ ¼
        clean_content = marker_match.group(2)
        return marker, clean_content
    # ä¿ç•™ç©ºæ ¼
    return '', content


def calculate_lrc_end_time(begin_time_str, next_begin_time_str=None, default_duration_ms=5000):
    """è®¡ç®—LRCè¡Œçš„ç»“æŸæ—¶é—´"""
    # è§£æå½“å‰å¼€å§‹æ—¶é—´
    time_parts = begin_time_str.split(':')
    min = int(time_parts[0])
    sec_parts = time_parts[1].split('.')
    sec = int(sec_parts[0])
    ms = int(sec_parts[1])

    begin_ms = (min * 60 + sec) * 1000 + ms

    # å¦‚æœæœ‰ä¸‹ä¸€è¡Œæ—¶é—´ï¼Œä½¿ç”¨ä¸‹ä¸€è¡Œæ—¶é—´ä½œä¸ºç»“æŸæ—¶é—´
    if next_begin_time_str:
        next_time_parts = next_begin_time_str.split(':')
        next_min = int(next_time_parts[0])
        next_sec_parts = next_time_parts[1].split('.')
        next_sec = int(next_sec_parts[0])
        next_ms = int(next_sec_parts[1])

        next_begin_ms = (next_min * 60 + next_sec) * 1000 + next_ms

        # å¦‚æœæ—¶é—´é—´éš”åˆç†ï¼ˆä¸è¶…è¿‡30ç§’ï¼‰ï¼Œä½¿ç”¨å®é™…é—´éš”
        if 0 < next_begin_ms - begin_ms < 30000:
            end_ms = next_begin_ms
        else:
            end_ms = begin_ms + default_duration_ms
    else:
        # æ²¡æœ‰ä¸‹ä¸€è¡Œï¼Œä½¿ç”¨é»˜è®¤æŒç»­æ—¶é—´
        end_ms = begin_ms + default_duration_ms

    # è½¬æ¢å›æ—¶é—´æ ¼å¼
    total_seconds = end_ms // 1000
    end_min = total_seconds // 60
    end_sec = total_seconds % 60
    end_ms_part = end_ms % 1000

    return f"{end_min:02d}:{end_sec:02d}.{end_ms_part:03d}"


def lrc_to_ttml(input_path, output_path):
    """å°†LRCæ ¼å¼è½¬æ¢ä¸ºTTMLæ ¼å¼ï¼ˆAppleé£æ ¼ï¼‰"""
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            lrc_content = f.read()

        # ---- è¯»å–å¹¶è§£æç¿»è¯‘ LRCï¼šè½¬æˆ æ¯«ç§’â†’æ–‡æœ¬ çš„å­—å…¸ï¼Œä¾›"ç²¾ç¡®åŒ¹é…" ----
        trans_path = find_translation_file(input_path)
        translation_dict_ms = {}
        if trans_path:
            try:
                with open(trans_path, 'r', encoding='utf-8') as f:
                    trans_content = f.read()
                trans_lines = [line.strip() for line in trans_content.split('\n') if line.strip()]
                for line in trans_lines:
                    begin_time_str, content = parse_lrc_line(line)  # "mm:ss.mmm"
                    if begin_time_str and content is not None:
                        begin_ms = ttml_time_to_ms(begin_time_str)
                        translation_dict_ms[begin_ms] = content
            except Exception as e:
                app.logger.warning(f"è¯»å–ç¿»è¯‘æ–‡ä»¶æ—¶å‡ºé”™: {trans_path}. é”™è¯¯: {str(e)}")

        # è§£æLRCå†…å®¹ï¼Œæå–æœ‰æ•ˆè¡Œ
        lines = [line.strip() for line in lrc_content.split('\n') if line.strip()]
        valid_lines = []

        # æ”¶é›†æ‰€æœ‰è¡Œçš„æ—¶é—´èŒƒå›´
        begin_times_ms = []
        end_times_ms = []
        for i, line in enumerate(lines):
            begin_time_str, content = parse_lrc_line(line)
            if begin_time_str and content:
                begin_ms = ttml_time_to_ms(begin_time_str)
                begin_times_ms.append(begin_ms)

                # è®¡ç®—ç»“æŸæ—¶é—´
                next_time = None
                if i+1 < len(lines):
                    next_begin_time_str, _ = parse_lrc_line(lines[i+1])
                    if next_begin_time_str:
                        next_time = next_begin_time_str
                end_time_str = calculate_lrc_end_time(begin_time_str, next_time)
                end_ms = ttml_time_to_ms(end_time_str)
                end_times_ms.append(end_ms)

        first_begin = min(begin_times_ms) if begin_times_ms else 0
        last_end = max(end_times_ms) if end_times_ms else 0

        # é‡æ–°è§£ææœ‰æ•ˆè¡Œï¼Œä½¿ç”¨æ¯«ç§’çº§ç²¾ç¡®ç¿»è¯‘åŒ¹é…
        for line in lines:
            begin_time_str, content = parse_lrc_line(line)
            if begin_time_str and content:
                # æå–æ ‡è®°å’Œæ¸…ç†å†…å®¹
                marker, clean_content = _extract_lrc_marker_and_clean(content)

                # æ£€æŸ¥æ˜¯å¦ä¸ºèƒŒæ™¯è¡Œ
                is_background = marker in ['6', '7', '8']

                # åŸºäºæ—¶é—´æˆ³è·å–å¯¹åº”çš„ç¿»è¯‘å†…å®¹ï¼ˆæ¯«ç§’çº§ç²¾ç¡®åŒ¹é…ï¼‰
                begin_ms = ttml_time_to_ms(begin_time_str)
                translation_content = translation_dict_ms.get(begin_ms)

                valid_lines.append({
                    'begin_time_str': begin_time_str,
                    'content': content,
                    'marker': marker,
                    'clean_content': clean_content,
                    'is_duet': '[2]' in content or '[5]' in content or marker in ['2', '5'],
                    'is_background': is_background,
                    'translation_content': translation_content
                })

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹å”±æ ‡è®°
        has_duet = any(line['is_duet'] for line in valid_lines)

        # åˆ›å»ºTTMLæ–‡æ¡£
        dom, div = create_ttml_document(has_duet)

        # è®¾ç½®bodyå’Œdivçš„æ—¶é—´èŒƒå›´
        body_elements = dom.getElementsByTagName('body')
        if body_elements:
            body = body_elements[0]
            body.setAttribute('dur', ms_to_ttml_time(last_end))

        if first_begin is not None:
            div.setAttribute('begin', ms_to_ttml_time(first_begin))
            div.setAttribute('end', ms_to_ttml_time(last_end))

        # è½¬æ¢æ¯ä¸€è¡Œ
        key_idx = 1
        prev_main_p = None

        for i, line_info in enumerate(valid_lines):
            begin_time_str = line_info['begin_time_str']
            clean_content = line_info['clean_content']
            marker = line_info['marker']
            is_duet = line_info['is_duet']
            is_background = line_info['is_background']
            translation_content = line_info['translation_content']

            if clean_content:
                # è®¡ç®—ç»“æŸæ—¶é—´
                next_time = valid_lines[i+1]['begin_time_str'] if i+1 < len(valid_lines) else None
                end_time_str = calculate_lrc_end_time(begin_time_str, next_time)
                begin_ms = ttml_time_to_ms(begin_time_str)
                end_ms = ttml_time_to_ms(end_time_str)

                if not is_background:
                    # åˆ›å»ºä¸»è¡Œpå…ƒç´ ï¼ˆAppleé£æ ¼ï¼‰
                    p = dom.createElement('p')
                    p.setAttribute('begin', begin_time_str)
                    p.setAttribute('end', end_time_str)
                    p.setAttribute('itunes:key', f'L{key_idx}')
                    p.setAttribute('ttm:agent', 'v1' if not is_duet else 'v2')
                    key_idx += 1

                    # æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹ï¼ˆAppleé£æ ¼ï¼‰
                    txt, tail_space = text_tail_space(clean_content)
                    if txt:
                        text_node = dom.createTextNode(txt)
                        p.appendChild(text_node)
                        if tail_space:
                            p.appendChild(dom.createTextNode(' '))

                    # å¦‚æœæœ‰ç¿»è¯‘å†…å®¹ï¼Œæ·»åŠ ç¿»è¯‘spanï¼ˆAppleé£æ ¼ï¼‰- ç²¾ç¡®åŒ¹é…
                    if translation_content:
                        trans_span = dom.createElement('span')
                        trans_span.setAttribute('ttm:role', 'x-translation')
                        trans_span.setAttribute('xml:lang', 'zh-CN')
                        trans_text = translation_content
                        trans_span.appendChild(dom.createTextNode(trans_text))
                        p.appendChild(trans_span)

                    div.appendChild(p)
                    prev_main_p = p
                else:
                    # èƒŒæ™¯è¡Œï¼šä½œä¸ºå†…åµŒspanæ·»åŠ åˆ°ä¸Šä¸€ä¸»è¡Œ
                    if prev_main_p is not None:
                        bg_span = dom.createElement('span')
                        bg_span.setAttribute('ttm:role', 'x-bg')
                        bg_span.setAttribute('begin', begin_time_str)
                        bg_span.setAttribute('end', end_time_str)

                        # æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹ï¼ˆèƒŒæ™¯ï¼‰
                        txt, tail_space = text_tail_space(clean_content)
                        if txt:
                            text_node = dom.createTextNode(txt)
                            bg_span.appendChild(text_node)
                            if tail_space:
                                bg_span.appendChild(dom.createTextNode(' '))

                        # å¦‚æœæœ‰ç¿»è¯‘å†…å®¹ï¼Œæ·»åŠ åˆ°èƒŒæ™¯spanä¸­ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
                        if translation_content:
                            trans_span = dom.createElement('span')
                            trans_span.setAttribute('ttm:role', 'x-translation')
                            trans_span.setAttribute('xml:lang', 'zh-CN')
                            trans_text = translation_content
                            trans_span.appendChild(dom.createTextNode(trans_text))
                            bg_span.appendChild(trans_span)

                        prev_main_p.appendChild(bg_span)
                    else:
                        # å¦‚æœæ²¡æœ‰ä¸Šä¸€ä¸»è¡Œï¼Œåˆ›å»ºä¸€ä¸ªä¸»è¡Œ
                        p = dom.createElement('p')
                        p.setAttribute('begin', begin_time_str)
                        p.setAttribute('end', end_time_str)
                        p.setAttribute('itunes:key', f'L{key_idx}')
                        p.setAttribute('ttm:agent', 'v1')
                        key_idx += 1

                        # èƒŒæ™¯ä½œä¸ºspanå†…åµŒ
                        bg_span = dom.createElement('span')
                        bg_span.setAttribute('ttm:role', 'x-bg')
                        bg_span.setAttribute('begin', begin_time_str)
                        bg_span.setAttribute('end', end_time_str)

                        # æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹ï¼ˆèƒŒæ™¯ï¼‰
                        txt, tail_space = text_tail_space(clean_content)
                        if txt:
                            text_node = dom.createTextNode(txt)
                            bg_span.appendChild(text_node)
                            if tail_space:
                                bg_span.appendChild(dom.createTextNode(' '))

                        # å¦‚æœæœ‰ç¿»è¯‘å†…å®¹ï¼Œæ·»åŠ åˆ°èƒŒæ™¯spanä¸­ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
                        if translation_content:
                            trans_span = dom.createElement('span')
                            trans_span.setAttribute('ttm:role', 'x-translation')
                            trans_span.setAttribute('xml:lang', 'zh-CN')
                            trans_text = translation_content
                            trans_span.appendChild(dom.createTextNode(trans_text))
                            bg_span.appendChild(trans_span)

                        p.appendChild(bg_span)
                        div.appendChild(p)
                        prev_main_p = p

        # å†™å…¥TTMLæ–‡ä»¶ï¼ˆå•è¡Œæ ¼å¼ï¼Œæ— æ¢è¡Œç¬¦å’Œç¼©è¿›ï¼‰
        with open(output_path, 'w', encoding='utf-8') as f:
            dom.writexml(f, indent='', addindent='', newl='', encoding='utf-8')

        return True, None
    except Exception as e:
        app.logger.error(f"æ— æ³•è½¬æ¢LRCåˆ°TTML: {input_path}. é”™è¯¯: {str(e)}")
        return False, str(e)

@app.route('/convert_ttml', methods=['POST'])
def convert_ttml():
    if not is_request_allowed():
        return abort(403)
    try:
        if 'file' not in request.files:
            return jsonify({'status': 'error', 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})

        file = request.files['file']
        if file.filename == '':
            return jsonify({'status': 'error', 'message': 'æ— æ•ˆçš„æ–‡ä»¶å'})

        # éªŒè¯æ–‡ä»¶ç±»å‹
        file_ext = Path(file.filename).suffix.lower()
        if file_ext != '.ttml':
            return jsonify({'status': 'error', 'message': 'åªæ”¯æŒTTMLæ ¼å¼'})

        # æ¸…ç†æ–‡ä»¶å
        clean_name = re.sub(r'[^\w\u4e00-\u9fa5-_.]', '', file.filename)
        temp_path = SONGS_DIR / f"temp_{clean_name}"

        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        file.save(temp_path)

        # è½¬æ¢TTMLæ–‡ä»¶
        try:
            success, lyric_path, trans_path = ttml_to_lys(str(temp_path), str(SONGS_DIR))
        except Exception as e:
            app.logger.error(f"TTMLè½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
            return jsonify({'status': 'error', 'message': f'TTMLè½¬æ¢å¤±è´¥: {str(e)}'})

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if temp_path.exists():
            try:
                temp_path.unlink()
            except Exception as e:
                app.logger.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {temp_path}: {str(e)}")

        if success:
            result = {
                'status': 'success',
                'lyricPath': f"http://127.0.0.1:5000/songs/{os.path.basename(lyric_path)}"
            }
            
            if trans_path:
                result['transPath'] = f"http://127.0.0.1:5000/songs/{os.path.basename(trans_path)}"
            
            return jsonify(result)
        else:
            return jsonify({'status': 'error', 'message': 'è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥TTMLæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®'})

    except Exception as e:
        app.logger.error(f"å¤„ç†TTMLè½¬æ¢è¯·æ±‚æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})

@app.route('/convert_ttml_by_path', methods=['POST'])
def convert_ttml_by_path():
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.get_json()
        ttml_filename = data.get('path')
        if not ttml_filename or not ttml_filename.lower().endswith('.ttml'):
            return jsonify({'status': 'error', 'message': 'è¯·æä¾›TTMLæ–‡ä»¶å'})
        ttml_path = SONGS_DIR / ttml_filename
        if not ttml_path.exists():
            return jsonify({'status': 'error', 'message': 'TTMLæ–‡ä»¶ä¸å­˜åœ¨'})
        # ç›´æ¥è°ƒç”¨åŸæœ‰è½¬æ¢é€»è¾‘
        success, lyric_path, trans_path = ttml_to_lys(str(ttml_path), str(SONGS_DIR))
        if success:
            result = {
                'status': 'success',
                'lyricPath': f'http://127.0.0.1:5000/songs/{os.path.basename(lyric_path)}'
            }
            if trans_path:
                result['transPath'] = f'http://127.0.0.1:5000/songs/{os.path.basename(trans_path)}'
            return jsonify(result)
        else:
            return jsonify({'status': 'error', 'message': 'è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥TTMLæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®'})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})

@app.route('/convert_to_ttml', methods=['POST'])
def convert_to_ttml():
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.get_json()
        lyrics_path = data.get('path')
        if not lyrics_path:
            return jsonify({'status': 'error', 'message': 'è¯·æä¾›æ­Œè¯æ–‡ä»¶è·¯å¾„'})

        # è·å–æ–‡ä»¶æ‰©å±•å
        file_ext = Path(lyrics_path).suffix.lower()
        if file_ext not in ['.lys', '.lrc']:
            return jsonify({'status': 'error', 'message': 'åªæ”¯æŒLYSå’ŒLRCæ ¼å¼'})

        # æ„å»ºå®Œæ•´è·¯å¾„
        input_path = SONGS_DIR / lyrics_path
        if not input_path.exists():
            return jsonify({'status': 'error', 'message': 'æ­Œè¯æ–‡ä»¶ä¸å­˜åœ¨'})

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_filename = input_path.stem + '.ttml'
        output_path = SONGS_DIR / output_filename

        # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ç›¸åº”çš„è½¬æ¢å‡½æ•°
        success = False
        error_msg = None
        if file_ext == '.lys':
            success, error_msg = lys_to_ttml(str(input_path), str(output_path))
        elif file_ext == '.lrc':
            success, error_msg = lrc_to_ttml(str(input_path), str(output_path))

        if success:
            return jsonify({
                'status': 'success',
                'ttmlPath': f"http://127.0.0.1:5000/songs/{output_filename}"
            })
        else:
            return jsonify({'status': 'error', 'message': f'è½¬æ¢å¤±è´¥: {error_msg}'})

    except Exception as e:
        app.logger.error(f"å¤„ç†è½¬æ¢è¯·æ±‚æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})


@app.route('/convert_to_ttml_temp', methods=['POST'])
def convert_to_ttml_temp():
    """å°†æ­Œè¯ä¸´æ—¶è½¬æ¢ä¸ºTTMLæ ¼å¼ï¼Œç”¨äºAMLLè§„åˆ™ç¼–å†™ï¼Œä¸è¦†ç›–åŸæ–‡ä»¶"""
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.get_json()
        lyrics_path = data.get('path')
        if not lyrics_path:
            return jsonify({'status': 'error', 'message': 'è¯·æä¾›æ­Œè¯æ–‡ä»¶è·¯å¾„'})

        # è·å–æ–‡ä»¶æ‰©å±•å
        file_ext = Path(lyrics_path).suffix.lower()
        if file_ext not in ['.lys', '.lrc']:
            return jsonify({'status': 'error', 'message': 'åªæ”¯æŒLYSå’ŒLRCæ ¼å¼'})

        # æ„å»ºå®Œæ•´è·¯å¾„
        input_path = SONGS_DIR / lyrics_path
        if not input_path.exists():
            return jsonify({'status': 'error', 'message': 'æ­Œè¯æ–‡ä»¶ä¸å­˜åœ¨'})

        # ç”Ÿæˆå¸¦ä¸“ç”¨åç¼€çš„ä¸´æ—¶è¾“å‡ºæ–‡ä»¶åï¼Œé¿å…å½±å“åŸæ–‡ä»¶
        output_filename = input_path.stem + '_amll_temp.ttml'
        output_path = SONGS_DIR / output_filename

        # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ç›¸åº”çš„è½¬æ¢å‡½æ•°
        success = False
        error_msg = None
        if file_ext == '.lys':
            success, error_msg = lys_to_ttml(str(input_path), str(output_path))
        elif file_ext == '.lrc':
            success, error_msg = lrc_to_ttml(str(input_path), str(output_path))

        if success:
            return jsonify({
                'status': 'success',
                'ttmlPath': f"http://127.0.0.1:5000/songs/{output_filename}"
            })
        else:
            return jsonify({'status': 'error', 'message': f'è½¬æ¢å¤±è´¥: {error_msg}'})

    except Exception as e:
        app.logger.error(f"å¤„ç†ä¸´æ—¶è½¬æ¢è¯·æ±‚æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})

@app.route('/merge_to_lqe', methods=['POST'])
def merge_to_lqe():
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.get_json()
        if not data or 'lyricsPath' not in data or 'translationPath' not in data:
            return jsonify({'status': 'error', 'message': 'ç¼ºå°‘å¿…è¦çš„å‚æ•°'})

        lyrics_path = data['lyricsPath']
        translation_path = data['translationPath']

        lyrics_filename = os.path.basename(lyrics_path)
        translation_filename = os.path.basename(translation_path)

        lyrics_full_path = SONGS_DIR / lyrics_filename
        translation_full_path = SONGS_DIR / translation_filename

        if not lyrics_full_path.exists() or not translation_full_path.exists():
            return jsonify({'status': 'error', 'message': 'æ‰¾ä¸åˆ°æ­Œè¯æˆ–ç¿»è¯‘æ–‡ä»¶'})

        with open(lyrics_full_path, 'r', encoding='utf-8') as f:
            lyrics_content = f.read()
        with open(translation_full_path, 'r', encoding='utf-8') as f:
            translation_content = f.read()

        # ç»„è£…LQEå†…å®¹
        lqe_content = "[lyrics: format@Lyricify Syllable]\n"
        lqe_content += lyrics_content.strip() + "\n\n"
        lqe_content += "[translation: format@LRC]\n"
        lqe_content += translation_content.strip() + "\n"

        return jsonify({
            'status': 'success',
            'content': lqe_content
        })

    except Exception as e:
        app.logger.error(f"åˆå¹¶LQEæ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})

@app.route('/extract_timestamps', methods=['POST'])
def extract_timestamps():
    try:
        data = request.json
        lyrics_content = data.get('content', '')
        app.logger.info(f"æ”¶åˆ°æ­Œè¯å†…å®¹ï¼Œé•¿åº¦: {len(lyrics_content)} å­—ç¬¦")
        
        # è®°å½•å†…å®¹æ‘˜è¦ï¼ˆå‰3è¡Œ+å3è¡Œï¼‰
        lines = lyrics_content.split('\n')
        if lines:
            preview_lines = lines[:3] + ['...'] + lines[-3:] if len(lines) > 6 else lines
            app.logger.debug(f"å†…å®¹é¢„è§ˆ: {preview_lines}")
        
        # å°†æ¯«ç§’è½¬æ¢ä¸ºåˆ†:ç§’.æ¯«ç§’æ ¼å¼
        def convert_milliseconds_to_time(milliseconds):
            total_seconds = milliseconds // 1000
            minutes = total_seconds // 60
            seconds = total_seconds % 60
            millis = milliseconds % 1000
            return f"{minutes:02d}:{seconds:02d}.{millis:03d}"
        
        # æå–æ—¶é—´æˆ³å¹¶è½¬æ¢ä¸ºLRCæ ¼å¼
        timestamps = []
        lines = lyrics_content.split('\n')
        app.logger.info(f"æ­Œè¯æ€»è¡Œæ•°: {len(lines)}")
        
        metadata_lines = 0
        empty_lines = 0
        processed_lines = 0
        
        for i, line in enumerate(lines, 1):
            if not line.strip():
                empty_lines += 1
                app.logger.debug(f"ç¬¬{i}è¡Œ: ç©ºè¡Œï¼Œè·³è¿‡")
                continue
                
            # è·³è¿‡å…ƒæ•°æ®è¡Œ
            if line.startswith('[by:') or line.startswith('[ti:') or line.startswith('[ar:'):
                metadata_lines += 1
                app.logger.debug(f"ç¬¬{i}è¡Œ: å…ƒæ•°æ®è¡Œ '{line[:50]}...'ï¼Œè·³è¿‡")
                continue
            
            # å¤„ç†æ‰€æœ‰ä»¥ [] æˆ– [æ•°å­—] å¼€å¤´çš„æ­Œè¯è¡Œ
            if re.match(r'^\[(\d*)\]', line):
                # åªåŒ¹é…ç¬¬ä¸€ä¸ªå·¦æ‹¬å·åé¢çš„å¼€å§‹æ—¶é—´
                match = re.search(r'\((\d+),', line)
                if match:
                    try:
                        timestamp = int(match.group(1))
                        time_str = convert_milliseconds_to_time(timestamp)
                        lrc_timestamp = f"[{time_str}]"
                        timestamps.append(lrc_timestamp)
                        processed_lines += 1
                        app.logger.debug(f"ç¬¬{i}è¡Œ: æˆåŠŸæå–æ—¶é—´æˆ³ '{lrc_timestamp}' (åŸå§‹å€¼: {match.group(1)}ms)")
                        app.logger.debug(f"ç¬¬{i}è¡Œå†…å®¹: '{line[:100]}...'" if len(line) > 100 else f"ç¬¬{i}è¡Œå†…å®¹: '{line}'")
                    except ValueError as e:
                        app.logger.warning(f"ç¬¬{i}è¡Œ: æ—¶é—´æˆ³è½¬æ¢å¤±è´¥ '{match.group(1)}', é”™è¯¯: {str(e)}")
                        continue
                else:
                    app.logger.debug(f"ç¬¬{i}è¡Œ: ç¬¦åˆæ­Œè¯è¡Œæ ¼å¼ä½†æœªæ‰¾åˆ°æ—¶é—´æˆ³ï¼Œè¡Œå†…å®¹: '{line[:100]}...'" if len(line) > 100 else f"ç¬¬{i}è¡Œ: ç¬¦åˆæ­Œè¯è¡Œæ ¼å¼ä½†æœªæ‰¾åˆ°æ—¶é—´æˆ³ï¼Œè¡Œå†…å®¹: '{line}'")
            else:
                app.logger.debug(f"ç¬¬{i}è¡Œ: ä¸ç¬¦åˆæ­Œè¯è¡Œæ ¼å¼ï¼Œè·³è¿‡ã€‚å†…å®¹: '{line[:100]}...'" if len(line) > 100 else f"ç¬¬{i}è¡Œ: ä¸ç¬¦åˆæ­Œè¯è¡Œæ ¼å¼ï¼Œè·³è¿‡ã€‚å†…å®¹: '{line}'")
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        app.logger.info(f"å¤„ç†ç»Ÿè®¡ - æ€»è¡Œæ•°: {len(lines)}, ç©ºè¡Œ: {empty_lines}, å…ƒæ•°æ®è¡Œ: {metadata_lines}, å¤„ç†è¡Œæ•°: {processed_lines}")
        app.logger.info(f"æˆåŠŸæå–æ—¶é—´æˆ³æ•°é‡: {len(timestamps)}")
        if timestamps:
            app.logger.info(f"ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³: {timestamps[0]}")
            app.logger.info(f"æœ€åä¸€ä¸ªæ—¶é—´æˆ³: {timestamps[-1]}")
        else:
            app.logger.warning("æœªæå–åˆ°ä»»ä½•æ—¶é—´æˆ³ï¼Œè¯·æ£€æŸ¥æ­Œè¯æ ¼å¼")
        
        return jsonify({
            'status': 'success',
            'timestamps': timestamps
        })
    except Exception as e:
        app.logger.error(f"æå–æ—¶é—´æˆ³æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})

@app.route('/extract_lyrics', methods=['POST'])
def extract_lyrics():
    try:
        data = request.json
        lyrics_content = data.get('content', '')
        app.logger.info(f"æ”¶åˆ°æ­Œè¯å†…å®¹ç”¨äºæå–æ­Œè¯æ–‡æœ¬ï¼Œé•¿åº¦: {len(lyrics_content)} å­—ç¬¦")
        
        # è®°å½•å†…å®¹æ‘˜è¦
        lines = lyrics_content.split('\n')
        app.logger.info(f"åŸå§‹æ­Œè¯æ€»è¡Œæ•°: {len(lines)}")
        if lines:
            preview_lines = lines[:3] + ['...'] + lines[-3:] if len(lines) > 6 else lines
            app.logger.debug(f"åŸå§‹å†…å®¹é¢„è§ˆ: {preview_lines}")
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ¯è¡Œæ­Œè¯ï¼ˆæ’é™¤æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
        extracted_lyrics = []
        empty_lines = 0
        processed_lines = 0
        filtered_lines = 0
        
        app.logger.info("å¼€å§‹å¤„ç†æ­Œè¯å†…å®¹...")
        extracted_lyrics = []
        
        # éå†æ¯è¡Œï¼Œæå–æ¯è¡Œä¸­çš„æ­Œè¯å¹¶å»é™¤æ—¶é—´æˆ³
        for line in lines:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»æ‰æ‰€æœ‰ä¸­æ‹¬å·åŠå…¶å†…å®¹ï¼Œä»¥åŠæ—¶é—´æˆ³éƒ¨åˆ†
            line_lyrics = re.sub(r'\[.*?\]', '', line)  # å»æ‰æ‰€æœ‰ä¸­æ‹¬å·åŠå…¶å†…å®¹
            line_lyrics = re.sub(r'\([0-9,]+\)', '', line_lyrics)  # å»æ‰æ—¶é—´æˆ³éƒ¨åˆ†
            line_lyrics = line_lyrics.strip()  # å»æ‰é¦–å°¾ç©ºç™½å­—ç¬¦
            if line_lyrics:  # å¦‚æœè¯¥è¡Œæœ‰æ­Œè¯å†…å®¹
                extracted_lyrics.append(line_lyrics)
        
        # å°†æ¯è¡Œæ­Œè¯æ·»åŠ æ¢è¡Œç¬¦
        cleaned_lyrics = '\n'.join(extracted_lyrics)
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        app.logger.info(f"æå–ç»Ÿè®¡ - æ€»è¡Œæ•°: {len(lines)}, ç©ºè¡Œ: {empty_lines}, è¿‡æ»¤è¡Œ: {filtered_lines}, æˆåŠŸæå–: {processed_lines}")
        app.logger.info(f"æœ€ç»ˆæå–æ­Œè¯å†…å®¹é•¿åº¦: {len(cleaned_lyrics)} å­—ç¬¦ï¼Œè¡Œæ•°: {len(extracted_lyrics)}")
        
        if extracted_lyrics:
            preview_extracted = extracted_lyrics[:3] + ['...'] + extracted_lyrics[-3:] if len(extracted_lyrics) > 6 else extracted_lyrics
            app.logger.debug(f"æå–ç»“æœé¢„è§ˆ: {preview_extracted}")
        else:
            app.logger.warning("æœªæå–åˆ°ä»»ä½•æ­Œè¯å†…å®¹")
        
        return jsonify({
            'status': 'success',
            'content': cleaned_lyrics
        })
    except Exception as e:
        app.logger.error(f"æå–æ­Œè¯æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'})

@app.route('/get_ai_settings', methods=['GET'])
def get_ai_settings():
    return jsonify({
        'status': 'success',
        'settings': AI_TRANSLATION_SETTINGS
    })

@app.route('/save_ai_settings', methods=['POST'])
def save_ai_settings():
    if not is_request_allowed():
        return abort(403)
    try:
        data = request.json
        global AI_TRANSLATION_SETTINGS
        AI_TRANSLATION_SETTINGS['api_key'] = data.get('api_key', '')
        AI_TRANSLATION_SETTINGS['system_prompt'] = data.get('system_prompt', AI_TRANSLATION_SETTINGS['system_prompt'])
        AI_TRANSLATION_SETTINGS['provider'] = data.get('provider', AI_TRANSLATION_SETTINGS['provider'])
        AI_TRANSLATION_SETTINGS['base_url'] = data.get('base_url', AI_TRANSLATION_SETTINGS['base_url'])
        AI_TRANSLATION_SETTINGS['model'] = data.get('model', AI_TRANSLATION_SETTINGS['model'])
        AI_TRANSLATION_SETTINGS['expect_reasoning'] = data.get('expect_reasoning', AI_TRANSLATION_SETTINGS['expect_reasoning'])
        return jsonify({
            'status': 'success',
            'api_key': AI_TRANSLATION_SETTINGS['api_key'],
            'system_prompt': AI_TRANSLATION_SETTINGS['system_prompt'],
            'provider': AI_TRANSLATION_SETTINGS['provider'],
            'base_url': AI_TRANSLATION_SETTINGS['base_url'],
            'model': AI_TRANSLATION_SETTINGS['model'],
            'expect_reasoning': AI_TRANSLATION_SETTINGS['expect_reasoning']
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})

@app.route('/probe_ai', methods=['POST'])
def probe_ai():
    if not is_request_allowed():
        return abort(403)
    try:
        request_data = request.get_json(silent=True) or {}
        api_key = request_data.get('api_key', '')
        base_url_raw = request_data.get('base_url') or AI_TRANSLATION_SETTINGS.get('base_url')

        # è§„èŒƒåŒ– base_urlï¼Œå»æ‰ç”¨æˆ·è¯¯å¡«çš„ /chat/completions ç­‰å°¾å·´
        def _normalize_base_url(u: str) -> str:
            if not u: return u
            u = u.strip().rstrip('/')
            import re
            return re.sub(r'/(chat|responses)/(completions|streams?)$', '', u, flags=re.I)

        base_url = _normalize_base_url(base_url_raw)
        if not api_key:
            return jsonify({'status': 'error', 'message': 'æœªæä¾›APIå¯†é’¥'})

        from openai import OpenAI
        client = OpenAI(api_key=api_key, base_url=base_url)
        models = client.models.list()
        names = [m.id for m in getattr(models, 'data', [])]
        return jsonify({'status': 'success', 'models': names[:200], 'base_url': base_url})
    except Exception as e:
        app.logger.error(f"æ¢æ´»AIæœåŠ¡æ—¶å‡ºé”™: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'æ¢æ´»å¤±è´¥: {e}', 'base_url': base_url_raw})

@app.route('/translate_lyrics', methods=['POST'])
def translate_lyrics():
    try:
        # è·å–è¯·æ±‚æ•°æ®
        request_data = request.get_json()
        content = request_data.get('content', '')
        api_key = request_data.get('api_key', '')
        # ä¼˜å…ˆç”¨å‰ç«¯ä¼ çš„ system_promptï¼Œæ²¡æœ‰åˆ™ç”¨å…¨å±€é»˜è®¤
        system_prompt = request_data.get('system_prompt') or AI_TRANSLATION_SETTINGS['system_prompt']

        # è·å–APIé…ç½®å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨è¯·æ±‚æ•°æ®ä¸­çš„å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨å…¨å±€é»˜è®¤å€¼
        provider = request_data.get('provider') or AI_TRANSLATION_SETTINGS['provider']
        base_url = request_data.get('base_url') or AI_TRANSLATION_SETTINGS['base_url']
        model = request_data.get('model') or AI_TRANSLATION_SETTINGS['model']
        expect_reasoning = request_data.get('expect_reasoning', AI_TRANSLATION_SETTINGS['expect_reasoning'])

        # è§„èŒƒåŒ– base_urlï¼Œè‡ªåŠ¨å‰”é™¤å¤šä½™è·¯å¾„
        def _normalize_base_url(u: str) -> str:
            if not u:
                return u
            u = u.strip().rstrip('/')
            # å»æ‰ç”¨æˆ·è¯¯å¡«çš„ /chat/completions æˆ– /responses/...
            import re
            u = re.sub(r'/(chat|responses)/(completions|streams?)$', '', u, flags=re.I)
            return u

        base_url = _normalize_base_url(base_url)

        if not content:
            return jsonify({'status': 'error', 'message': 'æœªæä¾›æ­Œè¯å†…å®¹'})

        if not api_key:
            return jsonify({'status': 'error', 'message': 'è¯·å…ˆè®¾ç½®APIå¯†é’¥'})

        # è·å–å®¢æˆ·ç«¯ä¿¡æ¯ç”¨äºæ—¥å¿—
        client_ip = request.remote_addr
        user_agent = request.headers.get('User-Agent', 'Unknown')
        request_id = f"{int(time.time()*1000)}_{random.randint(1000, 9999)}"
        
        app.logger.info("="*50)
        app.logger.info(f"å¼€å§‹å¤„ç†ç¿»è¯‘è¯·æ±‚ [ID: {request_id}]")
        app.logger.info(f"å®¢æˆ·ç«¯: {client_ip}, User-Agent: {user_agent}")
        app.logger.info(f"åŸå§‹æ­Œè¯å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        app.logger.info(f"APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '****'}")

        # 1. ä½¿ç”¨ç°æœ‰çš„æå–åŠŸèƒ½è·å–æ—¶é—´æˆ³å’Œæ­Œè¯
        timestamps_response = extract_timestamps()
        lyrics_response = extract_lyrics()
        
        # ä»å“åº”ä¸­è·å–æ•°æ®
        timestamps = timestamps_response.json.get('timestamps', [])
        lyrics = lyrics_response.json.get('content', '').split('\n')

        app.logger.info(f"æå–çš„æ—¶é—´æˆ³æ•°é‡: {len(timestamps)}")
        app.logger.info(f"æå–çš„æ­Œè¯è¡Œæ•°: {len(lyrics)}")
        app.logger.info(f"ç³»ç»Ÿæç¤ºè¯: {system_prompt[:100]}..." if len(system_prompt) > 100 else f"ç³»ç»Ÿæç¤ºè¯: {system_prompt}")

        # éªŒè¯æå–çš„å†…å®¹
        if not timestamps:
            app.logger.error("æœªæå–åˆ°ä»»ä½•æ—¶é—´æˆ³")
            return jsonify({'status': 'error', 'message': 'æœªæå–åˆ°ä»»ä½•æ—¶é—´æˆ³ï¼Œè¯·æ£€æŸ¥æ­Œè¯æ ¼å¼æ˜¯å¦æ­£ç¡®'})

        if not lyrics or all(not line.strip() for line in lyrics):
            app.logger.error("æœªæå–åˆ°ä»»ä½•æ­Œè¯å†…å®¹")
            return jsonify({'status': 'error', 'message': 'æœªæå–åˆ°ä»»ä½•æ­Œè¯å†…å®¹ï¼Œè¯·æ£€æŸ¥æ­Œè¯æ ¼å¼æ˜¯å¦æ­£ç¡®'})

        if len(timestamps) != len(lyrics):
            app.logger.error(f"æ—¶é—´æˆ³æ•°é‡({len(timestamps)})ä¸æ­Œè¯è¡Œæ•°({len(lyrics)})ä¸åŒ¹é…")
            return jsonify({'status': 'error', 'message': 'æ—¶é—´æˆ³æ•°é‡ä¸æ­Œè¯è¡Œæ•°ä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥æ­Œè¯æ ¼å¼æ˜¯å¦æ­£ç¡®'})

        # æ£€æŸ¥æ­Œè¯å†…å®¹æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦
        illegal_chars = ['content:', 'reasoning:']
        for i, line in enumerate(lyrics):
            for char in illegal_chars:
                if char in line:
                    app.logger.error(f"ç¬¬{i+1}è¡Œæ­Œè¯åŒ…å«éæ³•å­—ç¬¦: {char}")
                    return jsonify({'status': 'error', 'message': f'æ­Œè¯å†…å®¹åŒ…å«éæ³•å­—ç¬¦ï¼Œè¯·æ£€æŸ¥ç¬¬{i+1}è¡Œ'})

        # 2. è°ƒç”¨AIæœåŠ¡è¿›è¡Œç¿»è¯‘
        def generate():
            try:
                # æ„å»ºæç¤ºè¯
                numbered_lyrics = '\n'.join(f"{i+1}.{line}" for i, line in enumerate(lyrics))
                # ä½¿ç”¨ä¸Šé¢ä¼˜å…ˆçº§é€»è¾‘çš„ system_prompt
                app.logger.debug("å‘é€ç»™AIçš„æç¤ºè¯:")
                app.logger.debug(f"ç³»ç»Ÿæç¤ºè¯: {system_prompt}")
                app.logger.debug(f"ç”¨æˆ·è¾“å…¥æ‘˜è¦:\n{numbered_lyrics[:500]}..." if len(numbered_lyrics) > 500 else f"ç”¨æˆ·è¾“å…¥:\n{numbered_lyrics}")

                # è®°å½•APIè°ƒç”¨è¯¦ç»†ä¿¡æ¯
                app.logger.info(f"å‡†å¤‡è°ƒç”¨ {provider} API [ID: {request_id}]")
                app.logger.info(f"åŸºç¡€URL: {base_url}, æ¨¡å‹: {model}, æ­Œè¯è¡Œæ•°: {len(lyrics)}")
                app.logger.info(f"æç¤ºè¯é•¿åº¦: {len(numbered_lyrics)} å­—ç¬¦")
                app.logger.info(f"ç³»ç»Ÿæç¤ºè¯æ‘˜è¦: {system_prompt[:200]}..." if len(system_prompt) > 200 else f"ç³»ç»Ÿæç¤ºè¯: {system_prompt}")

                # è°ƒç”¨AIæœåŠ¡
                api_start_time = time.time()
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": numbered_lyrics}
                        ],
                        stream=True
                    )
                    api_call_success = True
                except Exception as api_error:
                    api_call_success = False
                    api_error_msg = str(api_error)
                    api_error_type = type(api_error).__name__
                    app.logger.error(f"APIè°ƒç”¨å¤±è´¥ [ID: {request_id}]: {api_error_type} - {api_error_msg}", exc_info=True)
                    raise

                # è®°å½•APIè°ƒç”¨æˆåŠŸ
                api_response_time = time.time() - api_start_time
                app.logger.info(f"APIè°ƒç”¨æˆåŠŸ [ID: {request_id}], å“åº”æ—¶é—´: {api_response_time:.2f}ç§’")

                # æ”¶é›†ç¿»è¯‘ç»“æœ
                full_translation = ""
                reasoning_content = ""
                current_reasoning = ""
                total_tokens = 0
                received_chunks = 0

                app.logger.info("å¼€å§‹æ¥æ”¶AIæµå¼å“åº”...")
                stream_start_time = time.time()
                for chunk in response:
                    received_chunks += 1
                    
                    # è®°å½•tokenä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœæœ‰ï¼‰
                    if hasattr(chunk, 'usage') and chunk.usage:
                        total_tokens = getattr(chunk.usage, 'total_tokens', 0)
                        
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ€ç»´é“¾å†…å®¹
                    if expect_reasoning and hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                        content = chunk.choices[0].delta.reasoning_content
                        current_reasoning += content
                        app.logger.debug(f"æ”¶åˆ°æ€ç»´é“¾å†…å®¹ [ID: {request_id}]: {content}")
                        # å‘é€æ€ç»´é“¾å†…å®¹
                        yield f"reasoning:{json.dumps({'reasoning': current_reasoning})}\n"
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ™®é€šå†…å®¹
                    if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_translation += content
                        app.logger.debug(f"æ”¶åˆ°ç¿»è¯‘å†…å®¹ [ID: {request_id}]: {content}")

                        # å¤„ç†ç¿»è¯‘å†…å®¹ï¼šä½¿ç”¨å­—å…¸æŒ‰è¡Œå·ç¨³å®šå¯¹é½ï¼ˆååˆ°çš„è¦†ç›–å…ˆåˆ°çš„ï¼‰
                        lines = full_translation.split('\n')
                        translated_dict = {}  # è¡Œå·(0-based) -> ç¿»è¯‘å†…å®¹
                        for line in lines:
                            if line.strip() and not line.startswith('æ€è€ƒ'):
                                # æå–åºå·å’Œç¿»è¯‘å†…å®¹
                                match = re.match(r'^(\d+)\.(.*)', line)
                                if match:
                                    line_num = int(match.group(1))  # 1-based
                                    content = match.group(2).strip()
                                    # è½¬ä¸º0-basedç´¢å¼•å¹¶å­˜å‚¨ï¼ˆååˆ°çš„è¦†ç›–å…ˆåˆ°çš„ï¼‰
                                    translated_dict[line_num - 1] = content

                        # ä½¿ç”¨å­—å…¸æŒ‰è¡Œå·ç¨³å®šå¯¹é½ï¼Œå³ä½¿è¡Œå·ä¹±åºæˆ–ç¼ºå¤±ä¹Ÿèƒ½æ­£ç¡®å¤„ç†
                        if translated_dict:
                            # æŒ‰æ—¶é—´æˆ³é¡ºåºæ„å»ºç¿»è¯‘ç»“æœï¼ˆä¸åŸæ–‡è¯åºä¸€è‡´ï¼‰
                            final_lyrics = []
                            for i, timestamp in enumerate(timestamps):
                                translation = translated_dict.get(i)  # è·å–å¯¹åº”è¡Œçš„ç¿»è¯‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                                if translation is not None:
                                    final_lyrics.append(f"{timestamp}{translation}")

                            # å‘é€ç¿»è¯‘å†…å®¹ï¼ˆåªå‘é€æœ‰ç¿»è¯‘çš„è¡Œï¼‰
                            if final_lyrics:
                                yield f"content:{json.dumps({'translations': final_lyrics})}\n"
                                app.logger.debug(f"æˆåŠŸåˆå¹¶ {len(final_lyrics)} è¡Œç¿»è¯‘æ­Œè¯")
                        else:
                            app.logger.warning("æœªæå–åˆ°æœ‰æ•ˆçš„ç¿»è¯‘å†…å®¹")
                            app.logger.debug(f"å½“å‰å®Œæ•´ç¿»è¯‘å†…å®¹é¢„è§ˆ:\n{full_translation[:500]}..." if len(full_translation) > 500 else f"å½“å‰å®Œæ•´ç¿»è¯‘å†…å®¹:\n{full_translation}")
                
                # è®°å½•æµå¼å“åº”å®Œæˆ
                stream_duration = time.time() - stream_start_time
                app.logger.info(f"æµå¼å“åº”å®Œæˆ [ID: {request_id}], è€—æ—¶: {stream_duration:.2f}ç§’")
                app.logger.info(f"æ€»å…±æ¥æ”¶ {received_chunks} ä¸ªæ•°æ®å—, ä¼°è®¡Tokenä½¿ç”¨: {total_tokens}")

            except Exception as e:
                error_time = time.time()
                error_duration = error_time - api_start_time
                app.logger.error(f"AIç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºé”™ [ID: {request_id}]: {str(e)}, æ€»è€—æ—¶: {error_duration:.2f}ç§’", exc_info=True)
                yield f"content:ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}\n"
            else:
                # è®°å½•ç¿»è¯‘æˆåŠŸå®Œæˆ
                total_duration = time.time() - api_start_time
                app.logger.info(f"ç¿»è¯‘æˆåŠŸå®Œæˆ [ID: {request_id}], æ€»è€—æ—¶: {total_duration:.2f}ç§’")
                app.logger.info(f"æœ€ç»ˆç¿»è¯‘å­—ç¬¦æ•°: {len(full_translation)}, æ€ç»´é“¾é•¿åº¦: {len(current_reasoning)}")
                app.logger.info(f"APIé…ç½®: {provider}, {base_url}, {model}, expect_reasoning: {expect_reasoning}")

        return Response(generate(), mimetype='text/event-stream')

    except Exception as e:
        error_type = type(e).__name__
        app.logger.error(f"å¤„ç†ç¿»è¯‘è¯·æ±‚æ—¶å‡ºé”™ [ID: {request_id if 'request_id' in locals() else 'N/A'}]: {error_type} - {str(e)}", exc_info=True)
        
        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_message = f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}'
        if 'request' in str(e).lower() or 'timeout' in str(e).lower():
            error_message += " (ç½‘ç»œæˆ–è¶…æ—¶é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥)"
        elif 'key' in str(e).lower() or 'auth' in str(e).lower():
            error_message += " (APIå¯†é’¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥å¯†é’¥æœ‰æ•ˆæ€§)"
        elif 'quota' in str(e).lower() or 'limit' in str(e).lower():
            error_message += " (é¢åº¦é™åˆ¶é—®é¢˜ï¼Œè¯·æ£€æŸ¥APIé¢åº¦)"
            
        return jsonify({'status': 'error', 'message': error_message})

@app.after_request
def add_header(resp):
    resp.headers['Access-Control-Allow-Origin'] = '*'
    return resp

@app.route('/lyrics-animate')
def lyrics_animate():
    file = request.args.get('file')
    style = request.args.get('style', 'Kok')  # é»˜è®¤ä¸º 'Kok'
    if not file:
        return "ç¼ºå°‘æ–‡ä»¶å‚æ•°", 400

    # âœ… è¯»å–ä¸´æ—¶è½¬æ¢å¾—åˆ°çš„å‚æ•°ï¼Œå¹¶å­˜å…¥ sessionï¼Œä¾› /lyrics ä½¿ç”¨
    lys_override = request.args.get('lys')
    lrc_override = request.args.get('lrc')
    if lys_override or lrc_override:
        session['override_lys_url'] = lys_override or None
        session['override_lrc_url'] = lrc_override or None
    else:
        session.pop('override_lys_url', None)
        session.pop('override_lrc_url', None)

    session['lyrics_json_file'] = file
    if style == 'äº®èµ·':
        return render_template('Lyrics-style.HTML')
    else:  # é»˜è®¤ä¸º 'Kok' æˆ–å…¶ä»–å€¼
        return render_template('Lyrics-style.HTML-v1.HTML')

@app.route('/lyrics')
def get_lyrics():
    """
    è·å–æ­Œè¯å’ŒéŸ³æºä¿¡æ¯
    æ”¯æŒçš„éŸ³ä¹æ ¼å¼ï¼š.mp3, .wav, .ogg, .mp4
    """
    json_file = session.get('lyrics_json_file', 'æµ‹è¯• - æµ‹è¯•.json')

    # âœ… ä¼˜å…ˆä½¿ç”¨ä¸´æ—¶è½¬æ¢å¾—åˆ°çš„è¦†ç›–åœ°å€ï¼ˆæ¥è‡ª /lyrics-animateï¼‰
    lys_url = session.get('override_lys_url')
    lrc_url = session.get('override_lrc_url')

    # å¦‚æœæ²¡æœ‰è¦†ç›–åœ°å€ï¼Œå†èµ°æ—§é€»è¾‘ï¼šä» JSON çš„ meta.lyrics é‡Œæ‰¾
    if not lys_url:
        json_path = os.path.join(app.static_folder, json_file)
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
            lyrics_info = meta_data.get('meta', {}).get('lyrics', '')
            lyric_sources = [src for src in lyrics_info.split('::') if src and src != '!']
            for src in lyric_sources:
                if src.endswith('.lys'):
                    lys_url = src
                if src.endswith('.lrc'):
                    lrc_url = lrc_url or src  # JSON é‡Œä¹Ÿå¯èƒ½æœ‰ç¿»è¯‘
        except FileNotFoundError:
            return jsonify({'error': 'å…ƒæ•°æ®JSONæœªæ‰¾åˆ°'}), 404
        except json.JSONDecodeError:
            return jsonify({'error': 'è§£æå…ƒæ•°æ®JSONæ—¶å‡ºé”™'}), 500

    if not lys_url:
        return jsonify({'error': '.lys æ–‡ä»¶é“¾æ¥æœªåœ¨å…ƒæ•°æ®æˆ–è¦†ç›–å‚æ•°ä¸­æ‰¾åˆ°'}), 404

    # è¯»å– LYS å†…å®¹
    from urllib.parse import urlparse
    parsed_url = urlparse(lys_url)
    lyrics_path = os.path.join(app.static_folder, parsed_url.path.lstrip('/'))
    try:
        with open(lyrics_path, 'r', encoding='utf-8-sig') as f:
            lys_content = f.read()
    except FileNotFoundError:
        return jsonify({'error': 'LYS æ­Œè¯æ–‡ä»¶æœªæ‰¾åˆ°'}), 404

    parsed_lyrics = parse_lys(lys_content)

    # æ–°å¢ï¼šæå– offset
    offset = 0
    offset_match = re.search(r'\[offset:\s*(-?\d+)\s*\]', lys_content)
    if offset_match:
        offset = int(offset_match.group(1))

    # è§£æç¿»è¯‘ï¼ˆä¼˜å…ˆä½¿ç”¨è¦†ç›–çš„ lrc_urlï¼‰
    translation = []
    if lrc_url:
        parsed_lrc_url = urlparse(lrc_url)
        lrc_path = os.path.join(app.static_folder, parsed_lrc_url.path.lstrip('/'))
        if os.path.exists(lrc_path):
            with open(lrc_path, 'r', encoding='utf-8') as f:
                lrc_content = f.read()
            translation = parse_lrc(lrc_content, offset=offset)  # ä¼ é€’ offset

    return jsonify({'lyrics': parsed_lyrics, 'translation': translation})

@app.route('/export_lyrics_csv', methods=['POST'])
def export_lyrics_csv():
    try:
        data = request.get_json()
        lyrics_data = data.get('lyrics', [])

        if not lyrics_data:
            return jsonify({'status': 'error', 'message': 'æœªæä¾›æ­Œè¯æ•°æ®'}), 400

        # å¯¼å‡ºé€å­—CSV
        csv_path = extract_lyrics_to_csv(lyrics_data)

        if csv_path:
            return jsonify({
                'status': 'success',
                'message': f'å¯¼å‡ºå®Œæˆï¼Œå…±å¯¼å‡º{len([c for line in lyrics_data for w in line.get("words", []) for c in w.get("word", "")])}ä¸ªå­—ç¬¦',
                'csv_path': str(csv_path)
            })
        else:
            return jsonify({'status': 'error', 'message': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ­Œè¯æ•°æ®'})

    except Exception as e:
        app.logger.error(f"å¯¼å‡ºCSVæ—¶å‡ºé”™: {str(e)}", exc_info=True)
        return jsonify({'status': 'error', 'message': f'å¯¼å‡ºå¤±è´¥: {str(e)}'})

@app.route('/get_json_data')
def get_json_data():
    filename = request.args.get('filename')
    if not filename:
        return jsonify({'status': 'error', 'message': 'ç¼ºå°‘æ–‡ä»¶åå‚æ•°'}), 400
    
    json_path = BASE_PATH / 'static' / filename
    if not json_path.exists():
        return jsonify({'status': 'error', 'message': 'JSONæ–‡ä»¶æœªæ‰¾åˆ°'}), 404
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        return jsonify({'status': 'success', 'jsonData': json_data})
    except Exception as e:
        return jsonify({'status': 'error', 'message': f'è¯»å–JSONæ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

@app.route('/get_lyrics', methods=['POST'])
def get_lyrics_by_path():
    try:
        data = request.get_json()
        lyrics_path = data.get('path', '')
        if not lyrics_path:
            return jsonify({'status': 'error', 'message': 'ç¼ºå°‘æ­Œè¯è·¯å¾„'}), 400

        # åªå…è®¸è¯»å– static/songs ä¸‹çš„æ­Œè¯æ–‡ä»¶
        if not lyrics_path.startswith('http://127.0.0.1:5000/songs/'):
            return jsonify({'status': 'error', 'message': 'è·¯å¾„ä¸åˆæ³•'}), 400

        real_path = Path(lyrics_path.replace('http://127.0.0.1:5000/songs/', str(SONGS_DIR) + '/'))
        if not real_path.exists():
            return jsonify({'status': 'error', 'message': 'æ­Œè¯æ–‡ä»¶æœªæ‰¾åˆ°'}), 404

        with open(real_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return jsonify({'status': 'success', 'content': content})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/song-info')
def song_info():
    json_file = session.get('lyrics_json_file', 'æµ‹è¯• - æµ‹è¯•.json')
    json_path = os.path.join(app.static_folder, json_file)
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data_str = f.read()

        # åŠ¨æ€æ›¿æ¢ host å’Œä¿®å¤è·¯å¾„ï¼Œä»¥é€‚é…å±€åŸŸç½‘è®¿é—®
        host = request.host
        # æ›¿æ¢ host (127.0.0.1 or localhost)
        data_str = re.sub(r'http://(127\.0\.0\.1|localhost):\d+', f'http://{host}', data_str)
        # ä¿®å¤è·¯å¾„ (ç§»é™¤ /static/)
        data_str = data_str.replace('/static/songs/', '/songs/')

        data = json.loads(data_str)
        return jsonify(data)
    except FileNotFoundError:
        return jsonify({'error': 'Song info file not found'}), 404
    except json.JSONDecodeError:
        return jsonify({'error': 'Error decoding JSON'}), 500

def parse_lrc(lrc_content, offset=0):
    """
    è§£æLRCæ ¼å¼ç¿»è¯‘ï¼Œè¿”å› [{'time': 'mm:ss.sss', 'content': '...'}]
    æ”¯æŒ offsetï¼ˆæ¯«ç§’ï¼‰
    """
    result = []
    lrc_time_re = re.compile(r'\[(\d{2}):(\d{2})\.(\d{2,3})\]')
    for line in lrc_content.splitlines():
        match = lrc_time_re.match(line)
        if match:
            min, sec, ms = match.groups()
            if len(ms) == 2:
                ms = str(int(ms) * 10).zfill(3)
            # è®¡ç®—åŸå§‹æ¯«ç§’
            total_ms = int(min) * 60 * 1000 + int(sec) * 1000 + int(ms)
            # åŠ  offset
            total_ms += offset
            # é‡æ–°æ ¼å¼åŒ–
            minutes = total_ms // 60000
            seconds = (total_ms % 60000) // 1000
            millis = total_ms % 1000
            time_str = f"{minutes:02}:{seconds:02}.{millis:03}"
            content = lrc_time_re.sub('', line).strip()
            if content:
                result.append({'time': time_str, 'content': content})
    return result

def is_local_request():
    # åªå…è®¸çœŸæ­£çš„æœ¬åœ°å›ç¯åœ°å€
    remote = request.remote_addr
    
    # æ£€æŸ¥å®‰å…¨é…ç½®ï¼Œå¦‚æœç¦ç”¨åˆ™å…è®¸æ‰€æœ‰è®¿é—®
    security_config = get_security_config()
    if not security_config.get('security_enabled', True):
        return True
        
    return remote in ['127.0.0.1', '::1']

PORT_STATUS_FILE = BASE_PATH / 'port_status.json'
SECURITY_CONFIG_FILE = BASE_PATH / 'security_config.json'
TRUSTED_DEVICES_FILE = BASE_PATH / 'trusted_devices.json'

# å®‰å…¨é…ç½®é»˜è®¤å€¼
DEFAULT_SECURITY_CONFIG = {
    'security_enabled': True,
    'password_hash': '',
    'trusted_expire_days': 30
}

# è¯»å–å®‰å…¨é…ç½®
def get_security_config():
    if SECURITY_CONFIG_FILE.exists():
        try:
            with open(SECURITY_CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return DEFAULT_SECURITY_CONFIG

# ä¿å­˜å®‰å…¨é…ç½®
def save_security_config(config):
    with open(SECURITY_CONFIG_FILE, 'w', encoding='utf-8') as f:
        json.dump(config, f)

# å—ä¿¡ä»»è®¾å¤‡æ•°æ®ç»“æ„å’Œæ“ä½œå‡½æ•°

def get_or_set_device_id():
    """è·å–æˆ–è®¾ç½®è®¾å¤‡IDï¼Œé€šè¿‡HttpOnly Cookieå®ç°"""
    device_id = request.cookies.get('FEW_DEVICE_ID')
    if not device_id:
        device_id = str(uuid.uuid4())
        response = jsonify({})
        response.set_cookie(
            'FEW_DEVICE_ID',
            device_id,
            httponly=True,
            samesite='Lax',
            max_age=365*24*3600  # 1å¹´æœ‰æ•ˆæœŸ
        )
        return device_id, response
    return device_id, None

def load_trusted_devices():
    """åŠ è½½å—ä¿¡ä»»è®¾å¤‡åˆ—è¡¨"""
    if TRUSTED_DEVICES_FILE.exists():
        try:
            with open(TRUSTED_DEVICES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return {}

def save_trusted_devices(devices):
    """ä¿å­˜å—ä¿¡ä»»è®¾å¤‡åˆ—è¡¨"""
    with open(TRUSTED_DEVICES_FILE, 'w', encoding='utf-8') as f:
        json.dump(devices, f, indent=2)

def hash_password(password):
    """ä½¿ç”¨bcryptå“ˆå¸Œå¯†ç """
    
    salt = bcrypt.gensalt()
    return bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')

def verify_password(password, hashed_password):
    """éªŒè¯å¯†ç """
    
    try:
        return bcrypt.checkpw(password.encode('utf-8'), hashed_password.encode('utf-8'))
    except:
        return False

def is_trusted_device(device_id):
    """æ£€æŸ¥è®¾å¤‡æ˜¯å¦å—ä¿¡ä»»ä¸”æœªè¿‡æœŸ"""
    if not device_id:
        return False
        
    trusted_devices = load_trusted_devices()
    device_info = trusted_devices.get(device_id)
    
    if not device_info:
        return False
        
    # æ£€æŸ¥è¿‡æœŸæ—¶é—´
    security_config = get_security_config()
    expire_days = security_config.get('trusted_expire_days', 30)
    expire_seconds = expire_days * 24 * 3600
    
    last_seen = datetime.fromisoformat(device_info['last_seen'])
    if (datetime.now() - last_seen).total_seconds() > expire_seconds:
        # è‡ªåŠ¨åˆ é™¤è¿‡æœŸè®¾å¤‡
        del trusted_devices[device_id]
        save_trusted_devices(trusted_devices)
        return False
        
    # æ›´æ–°æœ€åè®¿é—®æ—¶é—´
    device_info['last_seen'] = datetime.now().isoformat()
    trusted_devices[device_id] = device_info
    save_trusted_devices(trusted_devices)
    
    return True

def is_request_allowed():
    """ç»Ÿä¸€çš„è¯·æ±‚æƒé™æ£€æŸ¥å‡½æ•°"""
    # è·å–å®‰å…¨é…ç½®
    security_config = get_security_config()
    
    # å®‰å…¨ä¿æŠ¤å…³é—­æ—¶å…è®¸æ‰€æœ‰è®¿é—®
    if not security_config.get('security_enabled', True):
        return True
        
    # æœ¬æœºå›ç¯åœ°å€å®Œå…¨æ”¾è¡Œ
    remote = request.remote_addr
    if remote in ['127.0.0.1', '::1']:
        return True
        
    # æ£€æŸ¥è®¾å¤‡æ˜¯å¦å—ä¿¡ä»»
    device_id = request.cookies.get('FEW_DEVICE_ID')
    if device_id and is_trusted_device(device_id):
        return True
        
    return False

# è®¤è¯ç›¸å…³APIç«¯ç‚¹
@app.route('/auth/login', methods=['POST'])
def auth_login():
    """è®¾å¤‡ç™»å½•è®¤è¯"""
    # è·å–è®¾å¤‡ID
    device_id, cookie_response = get_or_set_device_id()
    
    # è·å–å¯†ç 
    data = request.json
    if not data or 'password' not in data:
        return jsonify({'status': 'error', 'message': 'è¯·è¾“å…¥å¯†ç '}), 400
    
    password = data['password']
    
    # éªŒè¯å¯†ç 
    security_config = get_security_config()
    password_hash = security_config.get('password_hash', '')
    
    if not password_hash:
        return jsonify({'status': 'error', 'message': 'ç³»ç»Ÿæœªè®¾ç½®å¯†ç ï¼Œè¯·è”ç³»ç®¡ç†å‘˜'}), 401
    
    if not verify_password(password, password_hash):
        # è®°å½•å¤±è´¥çš„è®¤è¯å°è¯•
        app.logger.warning(f"è®¤è¯å¤±è´¥ - è®¾å¤‡ID: {device_id[:8]}..., IP: {request.remote_addr}, UAå“ˆå¸Œ: {hashlib.md5(request.headers.get('User-Agent', '').encode()).hexdigest()[:8]}")
        return jsonify({'status': 'error', 'message': 'å¯†ç é”™è¯¯'}), 401
    
    # æ·»åŠ è®¾å¤‡åˆ°å—ä¿¡ä»»åˆ—è¡¨
    trusted_devices = load_trusted_devices()
    now = datetime.now().isoformat()
    
    if device_id not in trusted_devices:
        trusted_devices[device_id] = {
            'created_at': now,
            'last_seen': now,
            'ua_hash': hashlib.md5(request.headers.get('User-Agent', '').encode()).hexdigest(),
            'ip': request.remote_addr
        }
    else:
        # æ›´æ–°æœ€åè®¿é—®æ—¶é—´
        trusted_devices[device_id]['last_seen'] = now
    
    save_trusted_devices(trusted_devices)
    
    # è®°å½•æˆåŠŸçš„è®¤è¯
    app.logger.info(f"è®¤è¯æˆåŠŸ - è®¾å¤‡ID: {device_id[:8]}..., IP: {request.remote_addr}")
    
    response = jsonify({
        'status': 'success',
        'trusted': True,
        'device_id': device_id[:8] + '...'  # åªè¿”å›éƒ¨åˆ†IDç”¨äºæ˜¾ç¤º
    })
    
    # å¦‚æœè®¾ç½®äº†æ–°Cookieï¼Œéœ€è¦åˆå¹¶å“åº”
    if cookie_response:
        response.set_cookie(
            'FEW_DEVICE_ID',
            device_id,
            httponly=True,
            samesite='Lax',
            max_age=365*24*3600
        )
    
    return response

@app.route('/auth/logout', methods=['POST'])
def auth_logout():
    """è®¾å¤‡ç™»å‡º"""
    device_id = request.cookies.get('FEW_DEVICE_ID')
    
    if device_id:
        trusted_devices = load_trusted_devices()
        if device_id in trusted_devices:
            del trusted_devices[device_id]
            save_trusted_devices(trusted_devices)
            app.logger.info(f"è®¾å¤‡ç™»å‡º - è®¾å¤‡ID: {device_id[:8]}..., IP: {request.remote_addr}")
    
    return jsonify({'status': 'success', 'trusted': False})

@app.route('/auth/status', methods=['GET'])
def auth_status():
    """è·å–è®¾å¤‡ä¿¡ä»»çŠ¶æ€"""
    security_config = get_security_config()
    device_id = request.cookies.get('FEW_DEVICE_ID')
    
    trusted = False
    if device_id and is_trusted_device(device_id):
        trusted = True
    
    return jsonify({
        'status': 'success',
        'trusted': trusted,
        'security_enabled': security_config.get('security_enabled', True),
        'has_password': bool(security_config.get('password_hash', ''))
    })

@app.route('/auth/set_password', methods=['POST'])
def auth_set_password():
    """è®¾ç½®å¯†ç ï¼ˆä»…æœ¬æœºå¯æ“ä½œï¼‰"""
    if not is_local_request():
        return abort(403)
    
    data = request.json
    if not data or 'password' not in data:
        return jsonify({'status': 'error', 'message': 'è¯·è¾“å…¥å¯†ç '}), 400
    
    password = data['password']
    
    # æ›´æ–°å®‰å…¨é…ç½®
    security_config = get_security_config()
    security_config['password_hash'] = hash_password(password)
    save_security_config(security_config)
    
    # æ¸…é™¤æ‰€æœ‰å—ä¿¡ä»»è®¾å¤‡ï¼ˆå®‰å…¨èµ·è§ï¼Œä¿®æ”¹å¯†ç åæ‰€æœ‰è®¾å¤‡éœ€è¦é‡æ–°è®¤è¯ï¼‰
    save_trusted_devices({})
    
    app.logger.info(f"å¯†ç å·²æ›´æ–° - æ“ä½œIP: {request.remote_addr}")
    
    return jsonify({'status': 'success', 'message': 'å¯†ç è®¾ç½®æˆåŠŸ'})

@app.route('/auth/trusted', methods=['GET'])
def auth_list_trusted():
    """æŸ¥çœ‹å—ä¿¡ä»»è®¾å¤‡åˆ—è¡¨ï¼ˆä»…æœ¬æœºå¯æ“ä½œï¼‰"""
    if not is_local_request():
        return abort(403)
    
    trusted_devices = load_trusted_devices()
    
    # æ ¼å¼åŒ–è®¾å¤‡ä¿¡æ¯ï¼Œéšè—å®Œæ•´ID
    formatted_devices = []
    for device_id, info in trusted_devices.items():
        formatted_devices.append({
            'device_id': device_id[:8] + '...',
            'created_at': info.get('created_at', ''),
            'last_seen': info.get('last_seen', ''),
            'ip': info.get('ip', ''),
            'ua_hash': info.get('ua_hash', '')[:8] + '...'
        })
    
    return jsonify({
        'status': 'success',
        'devices': formatted_devices,
        'total': len(formatted_devices)
    })

@app.route('/auth/revoke', methods=['POST'])
def auth_revoke_device():
    """åŠé”€æŒ‡å®šè®¾å¤‡ï¼ˆä»…æœ¬æœºå¯æ“ä½œï¼‰"""
    if not is_local_request():
        return abort(403)
    
    data = request.json
    if not data or 'device_id' not in data:
        return jsonify({'status': 'error', 'message': 'è¯·æä¾›è®¾å¤‡ID'}), 400
    
    device_id_prefix = data['device_id']
    
    trusted_devices = load_trusted_devices()
    revoked_count = 0
    
    # æŸ¥æ‰¾åŒ¹é…çš„è®¾å¤‡ID
    for device_id in list(trusted_devices.keys()):
        if device_id.startswith(device_id_prefix.replace('...', '')):
            del trusted_devices[device_id]
            revoked_count += 1
    
    save_trusted_devices(trusted_devices)
    
    app.logger.info(f"åŠé”€è®¾å¤‡ - æ“ä½œIP: {request.remote_addr}, åŠé”€æ•°é‡: {revoked_count}")
    
    return jsonify({
        'status': 'success',
        'message': f'å·²åŠé”€ {revoked_count} ä¸ªè®¾å¤‡',
        'revoked_count': revoked_count
    })

@app.route('/auth/revoke_all', methods=['POST'])
def auth_revoke_all():
    """åŠé”€æ‰€æœ‰è®¾å¤‡ï¼ˆä»…æœ¬æœºå¯æ“ä½œï¼‰"""
    if not is_local_request():
        return abort(403)
    
    trusted_devices = load_trusted_devices()
    revoked_count = len(trusted_devices)
    
    save_trusted_devices({})
    
    app.logger.info(f"åŠé”€æ‰€æœ‰è®¾å¤‡ - æ“ä½œIP: {request.remote_addr}, åŠé”€æ•°é‡: {revoked_count}")
    
    return jsonify({
        'status': 'success',
        'message': f'å·²åŠé”€æ‰€æœ‰ {revoked_count} ä¸ªè®¾å¤‡',
        'revoked_count': revoked_count
    })

# è¯»å–ç«¯å£çŠ¶æ€
def get_port_status():
    if PORT_STATUS_FILE.exists():
        try:
            with open(PORT_STATUS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return {'mode': 'normal', 'port': 5000}

# å†™å…¥ç«¯å£çŠ¶æ€
def set_port_status(mode, port):
    with open(PORT_STATUS_FILE, 'w', encoding='utf-8') as f:
        json.dump({'mode': mode, 'port': port}, f)

@app.route('/get_port_status')
def api_get_port_status():
    return jsonify(get_port_status())

@app.route('/get_security_status')
def api_get_security_status():
    return jsonify(get_security_config())

@app.route('/toggle_security', methods=['POST'])
def api_toggle_security():
    if not is_local_request():
        return abort(403)
    
    try:
        security_config = get_security_config()
        # åˆ‡æ¢å®‰å…¨çŠ¶æ€
        old_status = security_config.get('security_enabled', True)
        new_status = not old_status
        security_config['security_enabled'] = new_status
        save_security_config(security_config)
        
        # è®°å½•å®‰å…¨çŠ¶æ€å˜æ›´
        app.logger.info(f"å®‰å…¨ä¿æŠ¤çŠ¶æ€å˜æ›´ - æ“ä½œIP: {request.remote_addr}, æ—§çŠ¶æ€: {'å¼€å¯' if old_status else 'å…³é—­'}, æ–°çŠ¶æ€: {'å¼€å¯' if new_status else 'å…³é—­'}")
        
        return jsonify({
            'status': 'success',
            'security_enabled': security_config['security_enabled']
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)})

@app.route('/switch_port', methods=['POST'])
def api_switch_port():
    if not is_local_request():
        return abort(403)
    # ç”Ÿæˆéšæœºç«¯å£ï¼ˆ1025-65535ï¼Œé¿å¼€å¸¸ç”¨ç«¯å£ï¼‰
    import random
    for _ in range(10):
        port = random.randint(1025, 65535)
        if not is_port_in_use(port):
            print(f'[ç«¯å£åˆ‡æ¢] é€‰æ‹©éšæœºç«¯å£: {port}')
            set_port_status('random', port)
            print(f'[ç«¯å£åˆ‡æ¢] å·²å†™å…¥ port_status.json: mode=random, port={port}')
            # è®°å½•ç«¯å£åˆ‡æ¢å®¡è®¡æ—¥å¿—
            app.logger.info(f"ç«¯å£åˆ‡æ¢ - æ“ä½œIP: {request.remote_addr}, åˆ‡æ¢åˆ°éšæœºç«¯å£: {port}")
            # é‡å¯åˆ°æ–°ç«¯å£
            import sys, os
            import webbrowser
            webbrowser.open(f'http://127.0.0.1:{port}')
            os.execv(sys.executable, [sys.executable, __file__, str(port)])
            return jsonify({'status': 'success', 'port': port})
    return jsonify({'status': 'fail', 'message': 'æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£'}), 500

@app.route('/restore_port', methods=['POST'])
def api_restore_port():
    if not is_local_request():
        return abort(403)
    set_port_status('normal', 5000)
    print(f'[ç«¯å£æ¢å¤] å·²å†™å…¥ port_status.json: mode=normal, port=5000')
    # è®°å½•ç«¯å£æ¢å¤å®¡è®¡æ—¥å¿—
    app.logger.info(f"ç«¯å£æ¢å¤ - æ“ä½œIP: {request.remote_addr}, æ¢å¤åˆ°é»˜è®¤ç«¯å£: 5000")
    import sys, os
    import webbrowser
    webbrowser.open('http://127.0.0.1:5000')
    os.execv(sys.executable, [sys.executable, __file__, '5000'])
    return jsonify({'status': 'success'})

def restart_on_port(port):
    import time
    time.sleep(1)  # ç»™å‰ç«¯å“åº”æ—¶é—´
    python = sys.executable
    os.execv(python, [python, __file__, str(port)])

@app.route('/get_my_ip')
def get_my_ip():
    return jsonify({'remote_addr': request.remote_addr})

# ===== AMLL å®æ—¶æµ API =====
@app.route('/amll/state')
def amll_state_api():
    """AMLL çŠ¶æ€å¿«ç…§ API"""
    return jsonify({
        "song": AMLL_STATE["song"],
        "progress_ms": AMLL_STATE["progress_ms"],
        "lines": AMLL_STATE["lines"]
    })

@app.route('/amll/stream')
def amll_stream_api():
    """AMLL å®æ—¶äº‹ä»¶æµ API (Server-Sent Events)"""
    @stream_with_context
    def _gen():
        # å…ˆå‘ä¸€ä»½å®Œæ•´å¿«ç…§ï¼ˆè®©æ–°æ‰“å¼€çš„å‰ç«¯ç«‹åˆ»æœ‰å†…å®¹ï¼‰
        yield _sse("state", {
            "song": AMLL_STATE["song"],
            "progress_ms": AMLL_STATE["progress_ms"],
            "lines": AMLL_STATE["lines"]
        })
        # ç„¶åæŒç»­æ¨é€å¢é‡
        while True:
            try:
                evt = AMLL_QUEUE.get(timeout=15)
                yield _sse(evt["type"], evt["data"])
            except queue.Empty:
                # å¿ƒè·³ï¼šé˜²æ­¢ Nginx/æµè§ˆå™¨æ–­æµ
                yield ": keep-alive\n\n"
    return Response(_gen(), mimetype="text/event-stream")

@app.route('/lyrics-amll')
def lyrics_amll_page():
    """AMLL æ­Œè¯å±•ç¤ºé¡µé¢"""
    return render_template("Lyrics-style.HTML-AMLL.HTML")

# ===== AMLL CSV å¯¼å‡ºåŠŸèƒ½ =====
def norm_type(t):
    if not isinstance(t, str):
        return ""
    return t.replace("_", "").replace("-", "").lower()

def ms_to_ts(ms):
    ms = int(ms or 0)
    s, msec = divmod(ms, 1000)
    m, s = divmod(s, 60)
    return f"{m:02d}:{s:02d}.{msec:03d}"

def looks_cjk_or_kana(s):
    # ç²—ç•¥åˆ¤æ–­ï¼šåŒ…å«ä¸­æ—¥éŸ©ç»Ÿä¸€è¡¨æ„æ–‡å­—ã€å‡åã€å…¨è§’ç­‰ï¼Œå°±è®¤ä¸ºéœ€è¦ç²˜è¿
    for ch in s:
        code = ord(ch)
        if (
            0x3040 <= code <= 0x30FF or   # ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠ
            0x4E00 <= code <= 0x9FFF or   # CJKç»Ÿä¸€è¡¨æ„
            0x3400 <= code <= 0x4DBF or   # CJKæ‰©å±•A
            0xFF01 <= code <= 0xFF60 or   # åŠè§’/å…¨è§’æ ‡ç‚¹
            0x3000 <= code <= 0x303F      # CJKæ ‡ç‚¹
        ):
            return True
    return False

def join_line_text(words):
    # CJK/å‡åè¡Œç”¨"è¿å†™"ï¼Œå¦åˆ™è‹±æ–‡ç­‰ç”¨ç©ºæ ¼åˆ†è¯
    text = "".join(w.get("word", "") for w in words)
    return text if looks_cjk_or_kana(text) else " ".join(w.get("word", "") for w in words)

def split_word_to_chars(word_obj):
    """å°†ä¸€ä¸ª word æ‹†æˆé€å­—äº‹ä»¶ï¼š
       - è‹¥æœ¬èº«æ˜¯å•å­—ï¼Œç›´æ¥è¿”å›
       - è‹¥å¤šå­—ï¼Œåˆ™æŒ‰å­—ç¬¦ç­‰åˆ†æ—¶é—´ç‰‡ï¼›roman_word å°è¯•æŒ‰ç©ºæ ¼/è¿å­—ç¬¦å¯¹é½
    """
    w = str(word_obj.get("word", ""))
    rw = str(word_obj.get("romanWord", "") or "")
    s = int(word_obj.get("startTime") or 0)
    e = int(word_obj.get("endTime") or s)
    n = max(1, len(w))

    # å…ˆå‡†å¤‡ç½—é©¬é€å­—åˆ—è¡¨ï¼ˆå°½åŠ›åŒ¹é…ï¼‰
    if rw:
        parts = rw.replace("  ", " ").strip().split(" ")
        if len(parts) != n:
            parts = rw.split("-")
        if len(parts) != n:
            parts = list(rw) if len(rw) == n else [""] * n
        roman_candidates = parts
    else:
        roman_candidates = [""] * n

    if n == 1:
        return [{
            "char": w,
            "roman_char": roman_candidates[0] if roman_candidates else "",
            "start_ms": s,
            "end_ms": e
        }]

    # å¤šå­—ï¼šç­‰åˆ†æ—¶é—´ï¼ˆæœ€åä¸€æ®µåƒä½™æ•°ï¼Œä¿è¯ç«¯ç‚¹å¯¹é½ï¼‰
    dur = max(0, e - s)
    if dur <= 0:
        # æ²¡æœ‰æœ‰æ•ˆæ—¶é•¿ï¼Œå…¨éƒ¨ç”¨åŒä¸€ç¬æ—¶æˆ³
        return [{
            "char": ch,
            "roman_char": roman_candidates[i] if i < len(roman_candidates) else "",
            "start_ms": s, "end_ms": s
        } for i, ch in enumerate(w)]

    base = dur // n
    rem = dur % n
    out = []
    cur = s
    for i, ch in enumerate(w):
        seg = base + (1 if i < rem else 0)
        out.append({
            "char": ch,
            "roman_char": roman_candidates[i] if i < len(roman_candidates) else "",
            "start_ms": cur,
            "end_ms": cur + seg
        })
        cur += seg
    # é˜²å¾¡ï¼šæœ€åä¸€ä¸ªç«¯ç‚¹æ ¡æ­£ä¸º e
    if out:
        out[-1]["end_ms"] = e
    return out

def extract_lyrics_to_csv(lyrics_data):
    """å°†æ­Œè¯æ•°æ®å¯¼å‡ºä¸ºé€å­—CSVæ–‡ä»¶"""
    char_rows = []
    for i, line in enumerate(lyrics_data, start=1):
        words = line.get("words", [])
        is_bg = bool(line.get("isBG", False))
        is_duet = bool(line.get("isDuet", False))
        start_ms = int(line.get("startTime") or 0)
        end_ms = int(line.get("endTime") or 0)

        for j, wobj in enumerate(words, start=1):
            # æ‹†æˆé€å­—
            char_events = split_word_to_chars(wobj)
            for k, ev in enumerate(char_events, start=1):
                c = ev["char"]
                rc = ev["roman_char"]
                s = ev["start_ms"]
                e = ev["end_ms"]
                char_rows.append({
                    "line_index": i,
                    "word_index": j,
                    "char_index": k,
                    "char": c,
                    "roman_char": rc,
                    "start_ms": s,
                    "end_ms": e,
                    "start_ts": ms_to_ts(s),
                    "end_ts": ms_to_ts(e),
                    "is_bg": is_bg,
                    "is_duet": is_duet
                })

    # å†™CSVåˆ°å¯¼å‡ºç›®å½•
    if char_rows:
        csv_name = f"lyrics_chars_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        csv_path = EXPORTS_DIR / csv_name
        with open(csv_path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=[
                    "line_index", "word_index", "char_index",
                    "char", "roman_char",
                    "start_ms", "end_ms", "start_ts", "end_ts",
                    "is_bg", "is_duet"
                ]
            )
            writer.writeheader()
            writer.writerows(char_rows)

        print(f"é€å­—æ—¶é—´è½´å·²å¯¼å‡ºï¼š{csv_path}ï¼ˆå…± {len(char_rows)} ä¸ªå­—ç¬¦äº‹ä»¶ï¼‰")
        return csv_path
    return None

# ======= æ–°å¢ AMLL å®æ—¶æ¨é€åŠŸèƒ½å‡½æ•° =======
def _ms_to_sec(ms: int) -> float:
    """æ¯«ç§’è½¬ç§’ï¼Œä¿ç•™3ä½å°æ•°"""
    return round((ms or 0) / 1000.0, 3)

def _amll_publish(evt_type: str, data: dict):
    """å‘å¸ƒäº‹ä»¶åˆ°AMLLå‰ç«¯"""
    # æ›´æ–°å…¨å±€å¿«ç…§
    if evt_type == "lyrics":
        AMLL_STATE["lines"] = data.get("lines", [])
    elif evt_type == "progress":
        AMLL_STATE["progress_ms"] = int(data.get("progress_ms", 0))
    elif evt_type == "song":
        AMLL_STATE["song"] = data.get("song", {})
    AMLL_STATE["last_update"] = time.time()

    # æ¨é€åˆ°é˜Ÿåˆ—
    try:
        AMLL_QUEUE.put_nowait({"type": evt_type, "data": data})
    except queue.Full:
        app.logger.warning("AMLL é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒäº‹ä»¶")

def _sse(event: str, data: dict) -> str:
    """SSE æ ¼å¼ï¼ševent:<name>\ndata:<json>\n\n"""
    return f"event:{event}\ndata:{json.dumps(data, ensure_ascii=False)}\n\n"

def _amll_lines_to_front(payload_lines: list[dict]) -> list[dict]:
    """
    æŠŠ AMLL çš„ linesï¼ˆæ¯è¡ŒåŒ…å« words[]ï¼‰è½¬æ¢ä¸ºå‰ç«¯ç»Ÿä¸€çš„ç»“æ„ï¼š
      æ¯è¡Œ -> { syllables: [ {text,startTime,duration,roman?}, ... ] }
    """
    out_lines = []
    for line in payload_lines:
        words = line.get("words", [])
        syllables = []
        for wobj in words:
            # æ‹†æˆé€å­—
            for ev in split_word_to_chars(wobj):
                syllables.append({
                    "text": ev["char"],
                    "startTime": _ms_to_sec(ev["start_ms"]),
                    "duration": max(0.0, _ms_to_sec(ev["end_ms"] - ev["start_ms"])),
                    "roman": ev["roman_char"]
                })

        # ä¿æŒåŸæ ·ï¼Œä½†åŠ å…¥å‰ç«¯éœ€è¦çš„é¢å¤–å­—æ®µ
        out_lines.append({
            "syllables": syllables,
            "isBG": bool(line.get("isBG")),
            "isDuet": bool(line.get("isDuet")),
            "translatedLyric": line.get("translatedLyric", "") or ""
        })
    return out_lines

def is_port_in_use(port):
    import socket
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        result = s.connect_ex(('127.0.0.1', port)) == 0
        print(f'[ç«¯å£æ£€æµ‹] ç«¯å£ {port} æ˜¯å¦è¢«å ç”¨: {result}')
        return result

# === WebSocket æœåŠ¡ï¼ˆAMLL å¯¹æ¥ï¼šws://localhost:11444ï¼‰===
WS_HOST = ""          # ç›‘å¬æ‰€æœ‰åœ°å€ï¼ˆåŒæ—¶è¦†ç›– IPv4 / IPv6ï¼‰
WS_PORT = 11444

async def ws_handle(ws):
    peer = getattr(ws, "remote_address", None)
    print(f"[WS] å®¢æˆ·ç«¯è¿æ¥: {peer}")
    try:
        async for raw in ws:
            # äºŒè¿›åˆ¶å¸§ï¼šå¯èƒ½æ˜¯ TTML
            if isinstance(raw, (bytes, bytearray)):
                b = bytes(raw)
                try:
                    txt = b.decode("utf-8")
                except UnicodeDecodeError:
                    txt = None
                if txt and txt.lstrip().startswith("<"):
                    name = f"lyrics_ttml_{datetime.now().strftime('%Y%m%d_%H%M%S')}.ttml"
                    (EXPORTS_DIR / name).write_text(txt, encoding="utf-8")
                    print(f"[WS] æ”¶åˆ°äºŒè¿›åˆ¶ TTMLï¼Œå·²ä¿å­˜ exports/{name}")
                else:
                    name = f"lyrics_binary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.bin"
                    (EXPORTS_DIR / name).write_bytes(b)
                    print(f"[WS] æ”¶åˆ°äºŒè¿›åˆ¶å¸§ï¼ˆ{len(b)} bytesï¼‰ï¼Œå·²ä¿å­˜ exports/{name}")
                continue

            # æ–‡æœ¬å¸§ï¼šä¼˜å…ˆæŒ‰ JSON è§£æ
            try:
                msg = json.loads(raw)
            except json.JSONDecodeError:
                app.logger.info(f"[WS] æ”¶åˆ°åŸå§‹ TTML æ–‡æœ¬: {raw[:200]}...")
                continue

            mtype = norm_type(msg.get("type"))
            if mtype == "ping":
                await ws.send(json.dumps({"type": "pong"})); continue
            if mtype in ("initializev2","initialize","init"):
                print("[WS] åˆå§‹åŒ–"); await ws.send(json.dumps({"type": "connected"})); continue
            if mtype == "setmusicinfo":
                info = msg.get("value") or {}
                song = {
                    "musicName": info.get("musicName", ""),
                    "artists": [a.get("name", "") for a in info.get("artists", [])],
                    "duration": int(info.get("duration") or 0)
                }
                print("[WS] æ­Œæ›²å…ƒæ•°æ®ï¼š", song)
                _amll_publish("song", {"song": song})
                continue
            if mtype == "onplayprogress":
                prog = int((msg.get("value") or {}).get("progress") or 0)
                # ä¸æ‰“å°æ¯ç§’è¿›åº¦åˆ°æ§åˆ¶å°ï¼Œé¿å…åˆ·å±
                app.logger.debug(f"[WS] è¿›åº¦(ms)ï¼š{prog}")
                _amll_publish("progress", {"progress_ms": prog})
                continue
            if mtype in ("onresumed","onpaused"):
                app.logger.debug(f"[WS] æ’­æ”¾çŠ¶æ€ï¼š{mtype}"); continue

            # é€å­—å±•å¼€å¯¼å‡º
            if mtype == "setlyric":
                payload = msg.get("value", {}).get("data", [])
                print(f"[WS] æ”¶åˆ°æ­Œè¯ {len(payload)} è¡Œï¼ˆé€å­—å¯¼å‡ºï¼‰")
                rows = []
                for i, line in enumerate(payload, 1):
                    words = line.get("words", [])
                    line_text = join_line_text(words)
                    s_ms = int(line.get("startTime") or 0); e_ms = int(line.get("endTime") or 0)
                    print(f"{i:04d} [{ms_to_ts(s_ms)} â†’ {ms_to_ts(e_ms)}] {line_text}")
                    is_bg = bool(line.get("isBG", False)); is_duet = bool(line.get("isDuet", False))
                    for j, wobj in enumerate(words, 1):
                        for k, ev in enumerate(split_word_to_chars(wobj), 1):
                            rows.append({
                                "line_index": i, "word_index": j, "char_index": k,
                                "char": ev["char"], "roman_char": ev["roman_char"],
                                "start_ms": ev["start_ms"], "end_ms": ev["end_ms"],
                                "start_ts": ms_to_ts(ev["start_ms"]), "end_ts": ms_to_ts(ev["end_ms"]),
                                "is_bg": is_bg, "is_duet": is_duet
                            })
                if rows:
                    import csv
                    name = f"lyrics_chars_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    with open(EXPORTS_DIR / name, "w", encoding="utf-8-sig", newline="") as f:
                        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys())); writer.writeheader(); writer.writerows(rows)
                    print(f"[WS] é€å­— CSV å·²å¯¼å‡ºï¼šexports/{name}ï¼ˆ{len(rows)} æ¡ï¼‰")

                # è½¬å‘åˆ°å‰ç«¯ AMLL æµï¼ˆå…ˆè®¡ç®—æ¶ˆå¤±æ—¶æœºï¼‰
                lines_front = _amll_lines_to_front(payload)

                try:
                    compute_disappear_times(lines_front, delta1=500, delta2=0, t_anim=700)
                except Exception as e:
                    app.logger.warning(f"[WS] è®¡ç®—æ¶ˆå¤±æ—¶æœºå¤±è´¥ï¼Œé™çº§ç»§ç»­: {e}")

                total_syllables = sum(len(l.get('syllables', [])) for l in lines_front)
                print(f"[WS] æ”¶åˆ°æ­Œè¯ {len(payload)} è¡Œï¼Œå·²è½¬æ¢ä¸º {total_syllables} ä¸ªé€å­—å•å…ƒï¼ˆå« disappearTimeï¼‰")
                _amll_publish("lyrics", {"lines": lines_front})
                continue

            print("[WS] æœªçŸ¥æ¶ˆæ¯ï¼š", msg)
    except websockets.ConnectionClosed as e:
        print(f"[WS] æ–­å¼€: {peer}, code={e.code}, reason={e.reason!r}")
    except Exception as e:
        print("[WS] å¤„ç†å¼‚å¸¸ï¼š", e)

# --- WebSocket å¯åŠ¨ä¿®å¤ï¼šåœ¨æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­åˆ›å»º server ---
async def _ws_main():
    try:
        # åœ¨â€œå·²è¿è¡Œçš„äº‹ä»¶å¾ªç¯ä¸­â€åˆ›å»º server
        async with websockets.serve(
            ws_handle,                  # ä½ å·²æœ‰çš„æ¶ˆæ¯å¤„ç†å‡½æ•°
            WS_HOST, WS_PORT,
            ping_interval=None,
            ping_timeout=None,
            max_size=64 * 1024 * 1024
        ) as server:
            # æ‰“å°çœŸå®ç›‘å¬çš„ socketsï¼Œä¾¿äºè‡ªæ£€
            sockets = getattr(server, "sockets", []) or []
            addrs = []
            for s in sockets:
                try:
                    addrs.append(s.getsockname())
                except Exception:
                    pass
            print(f"[WS] å·²å¯åŠ¨ï¼šws://localhost:{WS_PORT}ï¼ˆç›‘å¬={WS_HOST or 'ALL'}ï¼Œsockets={addrs}ï¼‰")

            # é˜»å¡ä¿æŒè¿è¡Œ
            await asyncio.Future()
    except OSError as e:
        print(f"[WS] å¯åŠ¨å¤±è´¥ï¼š{e} â€”â€” å¤šåŠæ˜¯ç«¯å£è¢«å ç”¨æˆ–æƒé™é—®é¢˜")
    except Exception as e:
        import traceback
        print("[WS] æœªæ•è·å¼‚å¸¸ï¼š")
        traceback.print_exc()

def _run_ws_loop():
    # åœ¨çº¿ç¨‹é‡Œåˆ›å»ºå¹¶è¿è¡Œäº‹ä»¶å¾ªç¯
    asyncio.run(_ws_main())

def start_ws_server_once():
    # é¿å… Flask Debug reloader å¯ä¸¤é
    if os.environ.get("WERKZEUG_RUN_MAIN") == "true" or not app.debug:
        t = threading.Thread(target=_run_ws_loop, name="WS-Server", daemon=True)
        t.start()
        return t

if __name__ == '__main__':
    import random
    def try_run(port):
        try:
            # å¯åŠ¨æ—¶åŒæ­¥ port_status.json
            if port == 5000:
                set_port_status('normal', 5000)
            else:
                set_port_status('random', port)
            print(f'[å¯åŠ¨] å°è¯•ç«¯å£: {port}')
            url = f"http://127.0.0.1:{port}"
            webbrowser.open(url)
            # å†™å…¥å¯åŠ¨å‘½ä»¤åˆ°æ–‡ä»¶
            # æ£€æµ‹å½“å‰æ˜¯å¦æ˜¯exeæ–‡ä»¶è¿è¡Œ
            is_exe = getattr(sys, 'frozen', False)
            if is_exe:
                # exeæ¨¡å¼ä¸‹ï¼Œä½¿ç”¨å½“å‰å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
                exe_path = sys.executable
                startup_cmd = f"set USE_WAITRESS=1\n"
                startup_cmd += f"\"{exe_path}\" {port}\n"
            else:
                # å¼€å‘æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨python backend.py
                startup_cmd = f"set USE_WAITRESS=1\npython backend.py {port}\n"
            with open(BASE_PATH / 'last_startup.bat', 'w', encoding='utf-8') as f:
                f.write(startup_cmd)
            with open(BASE_PATH / 'last_startup.txt', 'w', encoding='utf-8') as f:
                f.write(startup_cmd)
            # æ£€æŸ¥æ˜¯å¦ç”¨waitresså¯åŠ¨
            if os.environ.get('USE_WAITRESS', '0') == '1':
                from waitress import serve
                # æ ‡å‡†åŒ–çš„ Waitress é…ç½®å‚æ•°
                serve(
                    app,
                    host='0.0.0.0',
                    port=port,
                    threads=int(os.getenv('WT_THREADS', 8)),             # çº¿ç¨‹æ•°
                    connection_limit=int(os.getenv('WT_CONN_LIMIT', 200)),# å¹¶å‘è¿æ¥ä¸Šé™
                    channel_timeout=int(os.getenv('WT_TIMEOUT', 30)),     # ç©ºé—²é€šé“è¶…æ—¶ï¼ˆç§’ï¼‰
                    backlog=int(os.getenv('WT_BACKLOG', 512)),            # åŠè¿æ¥é˜Ÿåˆ—
                    ident=None                                           # æœåŠ¡å™¨æ ‡è¯†
                )
            else:
                app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)
            return True
        except OSError as e:
            print(f'[å¯åŠ¨] ç«¯å£ {port} å¯åŠ¨å¤±è´¥: {e}')
            return False

    port = 5000
    if len(sys.argv) > 1:
        try:
            port = int(sys.argv[1])
            # éªŒè¯ç«¯å£èŒƒå›´ (1-65535)
            if port < 1 or port > 65535:
                print(f'[é”™è¯¯] ç«¯å£ {port} æ— æ•ˆï¼Œç«¯å£èŒƒå›´åº”ä¸º 1-65535ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 5000')
                port = 5000
            else:
                print(f'[ä¿¡æ¯] ä½¿ç”¨æŒ‡å®šç«¯å£: {port}')
        except ValueError:
            print(f'[é”™è¯¯] ç«¯å£å‚æ•° "{sys.argv[1]}" ä¸æ˜¯æœ‰æ•ˆæ•°å­—ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 5000')
            port = 5000
        except Exception as e:
            print(f'[é”™è¯¯] å¤„ç†ç«¯å£å‚æ•°æ—¶å‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 5000')
            port = 5000
    else:
        print('[ä¿¡æ¯] æœªæŒ‡å®šç«¯å£ï¼Œä½¿ç”¨é»˜è®¤ç«¯å£ 5000')
    
    print(f'[ä¸»è¿›ç¨‹å¯åŠ¨] sys.argv: {sys.argv}, æœ€ç»ˆå¯åŠ¨ç«¯å£: {port}')

    # å…ˆèµ· WSï¼Œå†èµ· Flask
    ws_thread = start_ws_server_once()

    if not try_run(port):
        # 5000ç«¯å£å¤±è´¥ï¼Œæ¢éšæœºç«¯å£
        for _ in range(10):
            random_port = random.randint(1025, 65535)
            if try_run(random_port):
                break